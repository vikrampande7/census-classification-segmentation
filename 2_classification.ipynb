{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvEQKGsm1LtF"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Mgvy3mcVxNMx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, MinMaxScaler, OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, average_precision_score, precision_recall_curve, auc)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "\n",
        "from imblearn.over_sampling import SMOTE, SMOTENC\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "\n",
        "import joblib\n",
        "import shap\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "SCALE_POS_WEIGHT = 187140 / 12382  # SCALE_POS_WEIGHT is approximately 15:1 from the ration of count in dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkBABKZMxFWR"
      },
      "outputs": [],
      "source": [
        "column_names = []\n",
        "with open('data/census-bureau.columns', 'r') as f:\n",
        "    for line in f:\n",
        "        column_names.append(line.strip().replace(\" \",\"_\"))\n",
        "\n",
        "df = pd.read_csv(\"data/census-bureau.data\", delimiter=\",\")\n",
        "df.columns = column_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc6GXnDFavv8"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NbvSG47Gz1hm"
      },
      "outputs": [],
      "source": [
        "df = df.copy()\n",
        "rename_dict = {\n",
        "    \"fill_inc_questionnaire_for_veteran's_admin\": \"fill_inc_questionnaire_for_veterans_admin\",\n",
        "    'migration_code-change_in_msa': 'migration_code_change_in_msa',\n",
        "    'migration_code-change_in_reg': 'migration_code_change_in_reg',\n",
        "    'migration_code-move_within_reg': 'migration_code_move_within_reg'\n",
        "}\n",
        "df['hispanic_origin'] = df['hispanic_origin'].fillna('Do not know')\n",
        "df.rename(columns=rename_dict, inplace=True)\n",
        "df['label'] = df['label'].map({'- 50000.':0, '50000+.':1})  # Map values to 1 & 0\n",
        "df['net_gains'] = (df['capital_gains'] + df['dividends_from_stocks'] - df['capital_losses'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JRsDJyNZ0xQW"
      },
      "outputs": [],
      "source": [
        "# based on the EDA in another file, dropping a few columns which do not add up significantly in model predictions.\n",
        "cols_to_drop = ['label', 'weight', 'capital_gains', 'dividends_from_stocks', 'capital_losses', 'fill_inc_questionnaire_for_veterans_admin', 'veterans_benefits', 'year',\n",
        "                'enroll_in_edu_inst_last_wk', 'citizenship', 'country_of_birth_self', 'region_of_previous_residence', 'state_of_previous_residence']\n",
        "\n",
        "X = df.drop(columns=cols_to_drop)\n",
        "y = df['label']\n",
        "census_weights = df['weight'].values                        # Get the sample weights for loss function while modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYFOtV0qkDSk"
      },
      "source": [
        "# Numeric and Categoritcal Transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vm7SfQZM1OsR"
      },
      "outputs": [],
      "source": [
        "# Get the Numeric and Categorical Features Separately\n",
        "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "cat_idx = [X.columns.get_loc(col) for col in categorical_features] # For SMOTENC\n",
        "\n",
        "# Transform the Features to Impute Missing values, with methods like (median, most_frequent, mean, etc) but this has already been taken care while preprocessing\n",
        "# Scale the numeric values, Encode the categorical values\n",
        "numeric_transformer = Pipeline(\n",
        "    steps=[\n",
        "        #('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Convert all the categorical features using OneHotEncoding for a few models and OrdinalEncoding for another for standardized conversion\n",
        "ohe_categorical_transformer = Pipeline(\n",
        "    steps=[\n",
        "        #('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "    ]\n",
        ")\n",
        "\n",
        "# OrdinalEncoding\n",
        "oe_categorical_transformer = Pipeline(\n",
        "    steps=[\n",
        "        #('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('encoder', OrdinalEncoder())\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Preprocess with the above Transformations for Linear models\n",
        "lr_preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', ohe_categorical_transformer, categorical_features)\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "# For Tree based or Ensemble Models, scaling numeric features is not required as algorithm handles outliers or min max value ranges\n",
        "# Separate Pipeline for RandomForest and HGB\n",
        "rf_hgb_based_preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', ohe_categorical_transformer, categorical_features)\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "# Separate Pipeline for XGB and LightGBM with OrdinalEncoding\n",
        "xgb_lgb_based_preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', oe_categorical_transformer, categorical_features)\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3LdRTS1koYV"
      },
      "source": [
        "# Train-Test-Val Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8PJOXkW1w_2",
        "outputId": "7813b81d-4d49-47e4-f9a4-0c01c88541f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original training shape:  (139659, 30)\n",
            "Original class distribution:\n",
            " label\n",
            "0    130992\n",
            "1      8667\n",
            "Name: count, dtype: int64\n",
            "\n",
            "After SMOTE:\n",
            "Resampled shape: (261984, 30)\n",
            "Resampled class distribution:\n",
            " label\n",
            "0    130992\n",
            "1    130992\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Divide the dataset into train test and validation\n",
        "# Keep a part of data completete UNSEEN as test set for inference\n",
        "# Out of the remaining data, divide the data furthermore into training and validation to get offline metrics\n",
        "# Add SMOTE Sampling only for Training data and not for the test data to avoid leakage and stratify label\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.15, stratify=y, random_state=7)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.1765, stratify=y_train_full, random_state=7)\n",
        "\n",
        "print(\"Original training shape: \", X_train.shape)\n",
        "print(\"Original class distribution:\\n\", y_train.value_counts())\n",
        "\n",
        "# SMOTE and resample - SMOTENC for mixed data types, it considers both categorical and numeric features\n",
        "# Using SMOTE here, so weights column in the dataset will become unnecessary while predicting, If SMOTE was not used, then weights column could be passed while fitting the model,\n",
        "# ignoring weights column while training\n",
        "sm = SMOTENC(categorical_features=cat_idx, sampling_strategy='auto', random_state=7)\n",
        "X_train_resampled, y_train_resampled = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"\\nAfter SMOTE:\")\n",
        "print(\"Resampled shape:\", X_train_resampled.shape)\n",
        "print(\"Resampled class distribution:\\n\", y_train_resampled.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ctx9TLZfymcX"
      },
      "source": [
        "# Training with Hyperparameter Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gfstS3op4pMS"
      },
      "outputs": [],
      "source": [
        "# Define Model Pipelines\n",
        "\n",
        "# Logistic Regression\n",
        "lrc = ImbPipeline(\n",
        "    steps=[\n",
        "        ('preprocessor', lr_preprocessor),\n",
        "        ('clf', LogisticRegression(max_iter=1000, class_weight='balanced', n_jobs=1))\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Random Forest Classifier\n",
        "rfc = ImbPipeline(\n",
        "    steps=[\n",
        "        ('preprocessor', rf_hgb_based_preprocessor),\n",
        "        ('clf', RandomForestClassifier(class_weight='balanced', n_jobs=-1, random_state=7))\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Histogram Gradient Boosting\n",
        "hgb = ImbPipeline(\n",
        "    steps=[\n",
        "        ('preprocessor', rf_hgb_based_preprocessor),\n",
        "        ('clf', HistGradientBoostingClassifier(random_state=7))\n",
        "    ]\n",
        ")\n",
        "\n",
        "# XGBoost\n",
        "xgb = ImbPipeline(\n",
        "    steps=[\n",
        "        ('preprocessor', xgb_lgb_based_preprocessor),\n",
        "        ('clf', XGBClassifier(\n",
        "            objective='binary:logistic',\n",
        "            use_label_encoder=False,\n",
        "            eval_metric='auc',\n",
        "            random_state=7,\n",
        "            n_jobs=-1,\n",
        "            scale_pos_weight=SCALE_POS_WEIGHT\n",
        "        ))\n",
        "    ]\n",
        ")\n",
        "\n",
        "# LightGBM\n",
        "lgbm = ImbPipeline(\n",
        "    steps=[\n",
        "        ('preprocessor', xgb_lgb_based_preprocessor),\n",
        "        ('clf', lgb.LGBMClassifier(\n",
        "            objective='binary',\n",
        "            metric='auc',\n",
        "            random_state=7,\n",
        "            n_jobs=-1,\n",
        "            scale_pos_weight=SCALE_POS_WEIGHT\n",
        "        ))\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ldPgVl_p5KvT"
      },
      "outputs": [],
      "source": [
        "# Define Hyperparameter Search Space\n",
        "logistic_regression_params = {\n",
        "    'clf__C': np.logspace(-2,2,20),\n",
        "    'clf__penalty': ['l2'],\n",
        "    'clf__solver': ['lbfgs', 'liblinear']\n",
        "}\n",
        "\n",
        "random_forest_params = {\n",
        "    'clf__n_estimators': [100, 200, 300, 500],\n",
        "    'clf__max_depth': [None, 5, 10, 20, 30],\n",
        "    'clf__min_samples_split': [2, 5, 10],\n",
        "    'clf__min_samples_leaf': [1, 2, 4],\n",
        "    'clf__max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'clf__bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "hist_gb_params = {\n",
        "    'clf__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'clf__max_depth': [None, 3, 5, 7, 10],\n",
        "    'clf__max_leaf_nodes': [15, 31, 63, 127],\n",
        "    'clf__min_samples_leaf': [20, 10, 5],\n",
        "    'clf__l2_regularization': [0.0, 0.1, 1.0],\n",
        "    'clf__max_bins': [255, 128, 64],\n",
        "}\n",
        "\n",
        "xgb_params = {\n",
        "    'clf__n_estimators': [100, 300, 500],\n",
        "    'clf__learning_rate': [0.01, 0.05, 0.1],\n",
        "    'clf__max_depth': [3, 5, 7, 9],\n",
        "    'clf__gamma': [0, 0.1, 0.5]\n",
        "}\n",
        "\n",
        "lgbm_params = {\n",
        "    'clf__n_estimators': [100, 300, 500],\n",
        "    'clf__learning_rate': [0.01, 0.05, 0.1],\n",
        "    'clf__num_leaves': [20, 31, 40],\n",
        "    'clf__min_child_samples': [10, 20, 30]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0q20J5hJ5h9r"
      },
      "outputs": [],
      "source": [
        "# Stratified Cross Validation Step\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1EcfnFAI5v18"
      },
      "outputs": [],
      "source": [
        "# Randomized search CV per model\n",
        "def run_search(pipeline, param_config, X_train, y_train, cv, n_iter=25):\n",
        "  search = RandomizedSearchCV(\n",
        "      pipeline,\n",
        "      param_distributions=param_config,\n",
        "      n_iter=n_iter,\n",
        "      scoring='roc_auc',\n",
        "      cv=cv,\n",
        "      n_jobs=1,\n",
        "      verbose=3,\n",
        "      random_state=7\n",
        "  )\n",
        "\n",
        "  search.fit(X_train, y_train)\n",
        "\n",
        "  return search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uQMW_VZ6eQt",
        "outputId": "f172ca21-1603-41dc-fde9-e8e218648e25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "XGBoost\n",
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
            "[CV 1/5] END clf__gamma=0.1, clf__learning_rate=0.05, clf__max_depth=5, clf__n_estimators=100;, score=nan total time=   1.9s\n",
            "[CV 2/5] END clf__gamma=0.1, clf__learning_rate=0.05, clf__max_depth=5, clf__n_estimators=100;, score=nan total time=   1.8s\n",
            "[CV 3/5] END clf__gamma=0.1, clf__learning_rate=0.05, clf__max_depth=5, clf__n_estimators=100;, score=0.963 total time=   1.5s\n",
            "[CV 4/5] END clf__gamma=0.1, clf__learning_rate=0.05, clf__max_depth=5, clf__n_estimators=100;, score=0.962 total time=   2.3s\n",
            "[CV 5/5] END clf__gamma=0.1, clf__learning_rate=0.05, clf__max_depth=5, clf__n_estimators=100;, score=0.963 total time=   1.5s\n",
            "[CV 1/5] END clf__gamma=0.5, clf__learning_rate=0.05, clf__max_depth=3, clf__n_estimators=100;, score=nan total time=   1.3s\n",
            "[CV 2/5] END clf__gamma=0.5, clf__learning_rate=0.05, clf__max_depth=3, clf__n_estimators=100;, score=nan total time=   1.3s\n",
            "[CV 3/5] END clf__gamma=0.5, clf__learning_rate=0.05, clf__max_depth=3, clf__n_estimators=100;, score=0.954 total time=   1.4s\n",
            "[CV 4/5] END clf__gamma=0.5, clf__learning_rate=0.05, clf__max_depth=3, clf__n_estimators=100;, score=0.954 total time=   1.4s\n",
            "[CV 5/5] END clf__gamma=0.5, clf__learning_rate=0.05, clf__max_depth=3, clf__n_estimators=100;, score=0.956 total time=   1.4s\n",
            "[CV 1/5] END clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=500;, score=nan total time=   4.6s\n",
            "[CV 2/5] END clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=500;, score=nan total time=   3.2s\n",
            "[CV 3/5] END clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=500;, score=0.972 total time=   3.3s\n",
            "[CV 4/5] END clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=500;, score=0.971 total time=   4.1s\n",
            "[CV 5/5] END clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=500;, score=0.973 total time=   3.1s\n",
            "[CV 1/5] END clf__gamma=0.5, clf__learning_rate=0.05, clf__max_depth=9, clf__n_estimators=100;, score=nan total time=   1.7s\n",
            "[CV 2/5] END clf__gamma=0.5, clf__learning_rate=0.05, clf__max_depth=9, clf__n_estimators=100;, score=nan total time=   1.8s\n",
            "[CV 3/5] END clf__gamma=0.5, clf__learning_rate=0.05, clf__max_depth=9, clf__n_estimators=100;, score=0.969 total time=   1.9s\n",
            "[CV 4/5] END clf__gamma=0.5, clf__learning_rate=0.05, clf__max_depth=9, clf__n_estimators=100;, score=0.969 total time=   1.8s\n",
            "[CV 5/5] END clf__gamma=0.5, clf__learning_rate=0.05, clf__max_depth=9, clf__n_estimators=100;, score=0.970 total time=   2.8s\n",
            "[CV 1/5] END clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=9, clf__n_estimators=300;, score=nan total time=   3.6s\n",
            "[CV 2/5] END clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=9, clf__n_estimators=300;, score=nan total time=   3.5s\n",
            "[CV 3/5] END clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=9, clf__n_estimators=300;, score=0.965 total time=   5.5s\n",
            "[CV 4/5] END clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=9, clf__n_estimators=300;, score=0.965 total time=   3.8s\n",
            "[CV 5/5] END clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=9, clf__n_estimators=300;, score=0.966 total time=   3.8s\n",
            "[CV 1/5] END clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=9, clf__n_estimators=100;, score=nan total time=   2.5s\n",
            "[CV 2/5] END clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=9, clf__n_estimators=100;, score=nan total time=   1.8s\n",
            "[CV 3/5] END clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=9, clf__n_estimators=100;, score=0.941 total time=   1.8s\n",
            "[CV 4/5] END clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=9, clf__n_estimators=100;, score=0.940 total time=   1.9s\n",
            "[CV 5/5] END clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=9, clf__n_estimators=100;, score=0.942 total time=   1.9s\n",
            "[CV 1/5] END clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=100;, score=nan total time=   1.7s\n",
            "[CV 2/5] END clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=100;, score=nan total time=   1.6s\n",
            "[CV 3/5] END clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=100;, score=0.970 total time=   2.7s\n",
            "[CV 4/5] END clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=100;, score=0.970 total time=   1.6s\n",
            "[CV 5/5] END clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=100;, score=0.971 total time=   1.7s\n",
            "[CV 1/5] END clf__gamma=0.5, clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=300;, score=nan total time=   2.5s\n",
            "[CV 2/5] END clf__gamma=0.5, clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=300;, score=nan total time=   2.4s\n",
            "[CV 3/5] END clf__gamma=0.5, clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=300;, score=0.954 total time=   4.1s\n",
            "[CV 4/5] END clf__gamma=0.5, clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=300;, score=0.954 total time=   2.5s\n",
            "[CV 5/5] END clf__gamma=0.5, clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=300;, score=0.955 total time=   2.5s\n",
            "[CV 1/5] END clf__gamma=0, clf__learning_rate=0.05, clf__max_depth=3, clf__n_estimators=300;, score=nan total time=   1.8s\n",
            "[CV 2/5] END clf__gamma=0, clf__learning_rate=0.05, clf__max_depth=3, clf__n_estimators=300;, score=nan total time=   1.8s\n",
            "[CV 3/5] END clf__gamma=0, clf__learning_rate=0.05, clf__max_depth=3, clf__n_estimators=300;, score=0.964 total time=   3.6s\n",
            "[CV 4/5] END clf__gamma=0, clf__learning_rate=0.05, clf__max_depth=3, clf__n_estimators=300;, score=0.964 total time=   2.0s\n",
            "[CV 5/5] END clf__gamma=0, clf__learning_rate=0.05, clf__max_depth=3, clf__n_estimators=300;, score=0.965 total time=   1.9s\n",
            "[CV 1/5] END clf__gamma=0.1, clf__learning_rate=0.05, clf__max_depth=5, clf__n_estimators=300;, score=nan total time=   2.3s\n",
            "[CV 2/5] END clf__gamma=0.1, clf__learning_rate=0.05, clf__max_depth=5, clf__n_estimators=300;, score=nan total time=   2.2s\n",
            "[CV 3/5] END clf__gamma=0.1, clf__learning_rate=0.05, clf__max_depth=5, clf__n_estimators=300;, score=0.969 total time=   4.1s\n",
            "[CV 4/5] END clf__gamma=0.1, clf__learning_rate=0.05, clf__max_depth=5, clf__n_estimators=300;, score=0.968 total time=   2.5s\n",
            "[CV 5/5] END clf__gamma=0.1, clf__learning_rate=0.05, clf__max_depth=5, clf__n_estimators=300;, score=0.969 total time=   2.4s\n",
            "[CV 1/5] END clf__gamma=0, clf__learning_rate=0.05, clf__max_depth=9, clf__n_estimators=300;, score=nan total time=   3.2s\n",
            "[CV 2/5] END clf__gamma=0, clf__learning_rate=0.05, clf__max_depth=9, clf__n_estimators=300;, score=nan total time=   4.9s\n",
            "[CV 3/5] END clf__gamma=0, clf__learning_rate=0.05, clf__max_depth=9, clf__n_estimators=300;, score=0.974 total time=   3.3s\n",
            "[CV 4/5] END clf__gamma=0, clf__learning_rate=0.05, clf__max_depth=9, clf__n_estimators=300;, score=0.974 total time=   3.3s\n",
            "[CV 5/5] END clf__gamma=0, clf__learning_rate=0.05, clf__max_depth=9, clf__n_estimators=300;, score=0.975 total time=   5.0s\n",
            "[CV 1/5] END clf__gamma=0, clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=500;, score=nan total time=   3.5s\n",
            "[CV 2/5] END clf__gamma=0, clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=500;, score=nan total time=   3.5s\n",
            "[CV 3/5] END clf__gamma=0, clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=500;, score=0.963 total time=   5.1s\n",
            "[CV 4/5] END clf__gamma=0, clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=500;, score=0.962 total time=   3.5s\n",
            "[CV 5/5] END clf__gamma=0, clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=500;, score=0.963 total time=   3.4s\n",
            "[CV 1/5] END clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=9, clf__n_estimators=300;, score=nan total time=   3.0s\n",
            "[CV 2/5] END clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=9, clf__n_estimators=300;, score=nan total time=   3.8s\n",
            "[CV 3/5] END clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=9, clf__n_estimators=300;, score=0.976 total time=   3.2s\n",
            "[CV 4/5] END clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=9, clf__n_estimators=300;, score=0.976 total time=   3.3s\n",
            "[CV 5/5] END clf__gamma=0.1, clf__learning_rate=0.1, clf__max_depth=9, clf__n_estimators=300;, score=0.976 total time=   5.0s\n",
            "[CV 1/5] END clf__gamma=0, clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=500;, score=nan total time=   2.5s\n",
            "[CV 2/5] END clf__gamma=0, clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=500;, score=nan total time=   2.5s\n",
            "[CV 3/5] END clf__gamma=0, clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=500;, score=0.968 total time=   2.6s\n",
            "[CV 4/5] END clf__gamma=0, clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=500;, score=0.967 total time=   4.2s\n",
            "[CV 5/5] END clf__gamma=0, clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=500;, score=0.968 total time=   2.5s\n",
            "[CV 1/5] END clf__gamma=0.5, clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=100;, score=nan total time=   1.5s\n",
            "[CV 2/5] END clf__gamma=0.5, clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=100;, score=nan total time=   1.4s\n",
            "[CV 3/5] END clf__gamma=0.5, clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=100;, score=0.968 total time=   1.5s\n",
            "[CV 4/5] END clf__gamma=0.5, clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=100;, score=0.967 total time=   1.5s\n",
            "[CV 5/5] END clf__gamma=0.5, clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=100;, score=0.968 total time=   2.8s\n",
            "[CV 1/5] END clf__gamma=0.5, clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=500;, score=nan total time=   3.6s\n",
            "[CV 2/5] END clf__gamma=0.5, clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=500;, score=nan total time=   3.7s\n",
            "[CV 3/5] END clf__gamma=0.5, clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=500;, score=0.963 total time=   4.9s\n",
            "[CV 4/5] END clf__gamma=0.5, clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=500;, score=0.962 total time=   3.6s\n",
            "[CV 5/5] END clf__gamma=0.5, clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=500;, score=0.963 total time=   3.7s\n",
            "[CV 1/5] END clf__gamma=0, clf__learning_rate=0.05, clf__max_depth=7, clf__n_estimators=500;, score=nan total time=   5.6s\n",
            "[CV 2/5] END clf__gamma=0, clf__learning_rate=0.05, clf__max_depth=7, clf__n_estimators=500;, score=nan total time=   3.8s\n",
            "[CV 3/5] END clf__gamma=0, clf__learning_rate=0.05, clf__max_depth=7, clf__n_estimators=500;, score=0.973 total time=   3.8s\n",
            "[CV 4/5] END clf__gamma=0, clf__learning_rate=0.05, clf__max_depth=7, clf__n_estimators=500;, score=0.973 total time=   5.8s\n",
            "[CV 5/5] END clf__gamma=0, clf__learning_rate=0.05, clf__max_depth=7, clf__n_estimators=500;, score=0.974 total time=   4.1s\n",
            "[CV 1/5] END clf__gamma=0.5, clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=500;, score=nan total time=   2.9s\n",
            "[CV 2/5] END clf__gamma=0.5, clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=500;, score=nan total time=   4.7s\n",
            "[CV 3/5] END clf__gamma=0.5, clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=500;, score=0.971 total time=   3.1s\n",
            "[CV 4/5] END clf__gamma=0.5, clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=500;, score=0.971 total time=   3.1s\n",
            "[CV 5/5] END clf__gamma=0.5, clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=500;, score=0.972 total time=   3.8s\n",
            "[CV 1/5] END clf__gamma=0.5, clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=300;, score=nan total time=   1.9s\n",
            "[CV 2/5] END clf__gamma=0.5, clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=300;, score=nan total time=   1.8s\n",
            "[CV 3/5] END clf__gamma=0.5, clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=300;, score=0.967 total time=   2.1s\n",
            "[CV 4/5] END clf__gamma=0.5, clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=300;, score=0.966 total time=   1.9s\n",
            "[CV 5/5] END clf__gamma=0.5, clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=300;, score=0.967 total time=   2.0s\n",
            "[CV 1/5] END clf__gamma=0.5, clf__learning_rate=0.1, clf__max_depth=9, clf__n_estimators=100;, score=nan total time=   3.4s\n",
            "[CV 2/5] END clf__gamma=0.5, clf__learning_rate=0.1, clf__max_depth=9, clf__n_estimators=100;, score=nan total time=   1.7s\n",
            "[CV 3/5] END clf__gamma=0.5, clf__learning_rate=0.1, clf__max_depth=9, clf__n_estimators=100;, score=0.973 total time=   1.7s\n",
            "[CV 4/5] END clf__gamma=0.5, clf__learning_rate=0.1, clf__max_depth=9, clf__n_estimators=100;, score=0.972 total time=   1.9s\n",
            "[CV 5/5] END clf__gamma=0.5, clf__learning_rate=0.1, clf__max_depth=9, clf__n_estimators=100;, score=0.973 total time=   1.8s\n",
            "[CV 1/5] END clf__gamma=0, clf__learning_rate=0.05, clf__max_depth=3, clf__n_estimators=100;, score=nan total time=   1.3s\n",
            "[CV 2/5] END clf__gamma=0, clf__learning_rate=0.05, clf__max_depth=3, clf__n_estimators=100;, score=nan total time=   1.3s\n",
            "[CV 3/5] END clf__gamma=0, clf__learning_rate=0.05, clf__max_depth=3, clf__n_estimators=100;, score=0.954 total time=   2.1s\n",
            "[CV 4/5] END clf__gamma=0, clf__learning_rate=0.05, clf__max_depth=3, clf__n_estimators=100;, score=0.954 total time=   1.3s\n",
            "[CV 5/5] END clf__gamma=0, clf__learning_rate=0.05, clf__max_depth=3, clf__n_estimators=100;, score=0.956 total time=   1.3s\n",
            "[CV 1/5] END clf__gamma=0.5, clf__learning_rate=0.01, clf__max_depth=7, clf__n_estimators=500;, score=nan total time=   4.1s\n",
            "[CV 2/5] END clf__gamma=0.5, clf__learning_rate=0.01, clf__max_depth=7, clf__n_estimators=500;, score=nan total time=   6.0s\n",
            "[CV 3/5] END clf__gamma=0.5, clf__learning_rate=0.01, clf__max_depth=7, clf__n_estimators=500;, score=0.966 total time=   4.1s\n",
            "[CV 4/5] END clf__gamma=0.5, clf__learning_rate=0.01, clf__max_depth=7, clf__n_estimators=500;, score=0.966 total time=   4.1s\n",
            "[CV 5/5] END clf__gamma=0.5, clf__learning_rate=0.01, clf__max_depth=7, clf__n_estimators=500;, score=0.967 total time=   6.0s\n",
            "[CV 1/5] END clf__gamma=0, clf__learning_rate=0.05, clf__max_depth=5, clf__n_estimators=100;, score=nan total time=   1.4s\n",
            "[CV 2/5] END clf__gamma=0, clf__learning_rate=0.05, clf__max_depth=5, clf__n_estimators=100;, score=nan total time=   1.4s\n",
            "[CV 3/5] END clf__gamma=0, clf__learning_rate=0.05, clf__max_depth=5, clf__n_estimators=100;, score=0.963 total time=   1.5s\n",
            "[CV 4/5] END clf__gamma=0, clf__learning_rate=0.05, clf__max_depth=5, clf__n_estimators=100;, score=0.962 total time=   1.4s\n",
            "[CV 5/5] END clf__gamma=0, clf__learning_rate=0.05, clf__max_depth=5, clf__n_estimators=100;, score=0.963 total time=   1.4s\n",
            "[CV 1/5] END clf__gamma=0, clf__learning_rate=0.01, clf__max_depth=9, clf__n_estimators=500;, score=nan total time=   6.3s\n",
            "[CV 2/5] END clf__gamma=0, clf__learning_rate=0.01, clf__max_depth=9, clf__n_estimators=500;, score=nan total time=   5.0s\n",
            "[CV 3/5] END clf__gamma=0, clf__learning_rate=0.01, clf__max_depth=9, clf__n_estimators=500;, score=0.969 total time=   6.8s\n",
            "[CV 4/5] END clf__gamma=0, clf__learning_rate=0.01, clf__max_depth=9, clf__n_estimators=500;, score=0.969 total time=   6.2s\n",
            "[CV 5/5] END clf__gamma=0, clf__learning_rate=0.01, clf__max_depth=9, clf__n_estimators=500;, score=0.970 total time=   6.8s\n",
            "[CV 1/5] END clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=7, clf__n_estimators=300;, score=nan total time=   3.0s\n",
            "[CV 2/5] END clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=7, clf__n_estimators=300;, score=nan total time=   2.9s\n",
            "[CV 3/5] END clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=7, clf__n_estimators=300;, score=0.960 total time=   3.9s\n",
            "[CV 4/5] END clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=7, clf__n_estimators=300;, score=0.961 total time=   3.0s\n",
            "[CV 5/5] END clf__gamma=0.1, clf__learning_rate=0.01, clf__max_depth=7, clf__n_estimators=300;, score=0.961 total time=   2.9s\n",
            "\n",
            "LightGBM\n",
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020006 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 1/5] END clf__learning_rate=0.1, clf__min_child_samples=10, clf__n_estimators=500, clf__num_leaves=40;, score=nan total time=   5.6s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010720 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 2/5] END clf__learning_rate=0.1, clf__min_child_samples=10, clf__n_estimators=500, clf__num_leaves=40;, score=nan total time=   3.9s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009543 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 3/5] END clf__learning_rate=0.1, clf__min_child_samples=10, clf__n_estimators=500, clf__num_leaves=40;, score=0.974 total time=   4.2s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013824 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 281\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 4/5] END clf__learning_rate=0.1, clf__min_child_samples=10, clf__n_estimators=500, clf__num_leaves=40;, score=0.974 total time=   4.6s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010007 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209588, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5] END clf__learning_rate=0.1, clf__min_child_samples=10, clf__n_estimators=500, clf__num_leaves=40;, score=0.975 total time=   4.1s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008890 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 1/5] END clf__learning_rate=0.05, clf__min_child_samples=20, clf__n_estimators=100, clf__num_leaves=20;, score=nan total time=   1.6s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009734 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 2/5] END clf__learning_rate=0.05, clf__min_child_samples=20, clf__n_estimators=100, clf__num_leaves=20;, score=nan total time=   2.8s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009576 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 3/5] END clf__learning_rate=0.05, clf__min_child_samples=20, clf__n_estimators=100, clf__num_leaves=20;, score=0.961 total time=   1.8s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010690 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 281\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 4/5] END clf__learning_rate=0.05, clf__min_child_samples=20, clf__n_estimators=100, clf__num_leaves=20;, score=0.961 total time=   1.8s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011178 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209588, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5] END clf__learning_rate=0.05, clf__min_child_samples=20, clf__n_estimators=100, clf__num_leaves=20;, score=0.962 total time=   1.7s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010469 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 1/5] END clf__learning_rate=0.1, clf__min_child_samples=10, clf__n_estimators=500, clf__num_leaves=20;, score=nan total time=   3.5s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008798 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 2/5] END clf__learning_rate=0.1, clf__min_child_samples=10, clf__n_estimators=500, clf__num_leaves=20;, score=nan total time=   5.0s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009157 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 3/5] END clf__learning_rate=0.1, clf__min_child_samples=10, clf__n_estimators=500, clf__num_leaves=20;, score=0.972 total time=   3.6s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009564 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 281\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 4/5] END clf__learning_rate=0.1, clf__min_child_samples=10, clf__n_estimators=500, clf__num_leaves=20;, score=0.972 total time=   3.5s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010281 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209588, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5] END clf__learning_rate=0.1, clf__min_child_samples=10, clf__n_estimators=500, clf__num_leaves=20;, score=0.973 total time=   5.4s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012518 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 1/5] END clf__learning_rate=0.01, clf__min_child_samples=20, clf__n_estimators=500, clf__num_leaves=40;, score=nan total time=   5.3s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010488 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 2/5] END clf__learning_rate=0.01, clf__min_child_samples=20, clf__n_estimators=500, clf__num_leaves=40;, score=nan total time=   6.8s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010501 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 3/5] END clf__learning_rate=0.01, clf__min_child_samples=20, clf__n_estimators=500, clf__num_leaves=40;, score=0.965 total time=   5.4s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009737 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 281\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 4/5] END clf__learning_rate=0.01, clf__min_child_samples=20, clf__n_estimators=500, clf__num_leaves=40;, score=0.965 total time=   7.1s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010467 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209588, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5] END clf__learning_rate=0.01, clf__min_child_samples=20, clf__n_estimators=500, clf__num_leaves=40;, score=0.965 total time=   5.4s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009043 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 1/5] END clf__learning_rate=0.05, clf__min_child_samples=20, clf__n_estimators=300, clf__num_leaves=40;, score=nan total time=   3.1s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035211 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 2/5] END clf__learning_rate=0.05, clf__min_child_samples=20, clf__n_estimators=300, clf__num_leaves=40;, score=nan total time=   5.0s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008391 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 3/5] END clf__learning_rate=0.05, clf__min_child_samples=20, clf__n_estimators=300, clf__num_leaves=40;, score=0.971 total time=   3.4s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010257 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 281\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 4/5] END clf__learning_rate=0.05, clf__min_child_samples=20, clf__n_estimators=300, clf__num_leaves=40;, score=0.971 total time=   3.4s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017174 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209588, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5] END clf__learning_rate=0.05, clf__min_child_samples=20, clf__n_estimators=300, clf__num_leaves=40;, score=0.972 total time=   5.2s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009718 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 1/5] END clf__learning_rate=0.01, clf__min_child_samples=20, clf__n_estimators=300, clf__num_leaves=20;, score=nan total time=   3.2s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009059 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 2/5] END clf__learning_rate=0.01, clf__min_child_samples=20, clf__n_estimators=300, clf__num_leaves=20;, score=nan total time=   3.0s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008559 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 3/5] END clf__learning_rate=0.01, clf__min_child_samples=20, clf__n_estimators=300, clf__num_leaves=20;, score=0.948 total time=   4.7s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010100 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 281\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 4/5] END clf__learning_rate=0.01, clf__min_child_samples=20, clf__n_estimators=300, clf__num_leaves=20;, score=0.947 total time=   3.1s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012345 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209588, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5] END clf__learning_rate=0.01, clf__min_child_samples=20, clf__n_estimators=300, clf__num_leaves=20;, score=0.949 total time=   3.1s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009216 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 1/5] END clf__learning_rate=0.05, clf__min_child_samples=10, clf__n_estimators=100, clf__num_leaves=20;, score=nan total time=   1.7s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009176 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 2/5] END clf__learning_rate=0.05, clf__min_child_samples=10, clf__n_estimators=100, clf__num_leaves=20;, score=nan total time=   1.8s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045559 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 3/5] END clf__learning_rate=0.05, clf__min_child_samples=10, clf__n_estimators=100, clf__num_leaves=20;, score=0.962 total time=   2.2s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010108 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 281\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 4/5] END clf__learning_rate=0.05, clf__min_child_samples=10, clf__n_estimators=100, clf__num_leaves=20;, score=0.962 total time=   1.7s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014252 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209588, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5] END clf__learning_rate=0.05, clf__min_child_samples=10, clf__n_estimators=100, clf__num_leaves=20;, score=0.962 total time=   1.8s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010395 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 1/5] END clf__learning_rate=0.01, clf__min_child_samples=20, clf__n_estimators=500, clf__num_leaves=20;, score=nan total time=   4.3s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007718 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 2/5] END clf__learning_rate=0.01, clf__min_child_samples=20, clf__n_estimators=500, clf__num_leaves=20;, score=nan total time=   6.1s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010687 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 3/5] END clf__learning_rate=0.01, clf__min_child_samples=20, clf__n_estimators=500, clf__num_leaves=20;, score=0.962 total time=   4.8s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008634 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 281\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 4/5] END clf__learning_rate=0.01, clf__min_child_samples=20, clf__n_estimators=500, clf__num_leaves=20;, score=0.961 total time=   6.3s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010782 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209588, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5] END clf__learning_rate=0.01, clf__min_child_samples=20, clf__n_estimators=500, clf__num_leaves=20;, score=0.962 total time=   4.5s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010667 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 1/5] END clf__learning_rate=0.05, clf__min_child_samples=20, clf__n_estimators=300, clf__num_leaves=31;, score=nan total time=   2.8s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010024 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 2/5] END clf__learning_rate=0.05, clf__min_child_samples=20, clf__n_estimators=300, clf__num_leaves=31;, score=nan total time=   4.8s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009121 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 3/5] END clf__learning_rate=0.05, clf__min_child_samples=20, clf__n_estimators=300, clf__num_leaves=31;, score=0.970 total time=   3.3s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009619 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 281\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 4/5] END clf__learning_rate=0.05, clf__min_child_samples=20, clf__n_estimators=300, clf__num_leaves=31;, score=0.970 total time=   3.2s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011516 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209588, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5] END clf__learning_rate=0.05, clf__min_child_samples=20, clf__n_estimators=300, clf__num_leaves=31;, score=0.971 total time=   3.9s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011182 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 1/5] END clf__learning_rate=0.01, clf__min_child_samples=10, clf__n_estimators=100, clf__num_leaves=40;, score=nan total time=   1.7s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011126 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 2/5] END clf__learning_rate=0.01, clf__min_child_samples=10, clf__n_estimators=100, clf__num_leaves=40;, score=nan total time=   1.8s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010534 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 3/5] END clf__learning_rate=0.01, clf__min_child_samples=10, clf__n_estimators=100, clf__num_leaves=40;, score=0.926 total time=   1.8s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010657 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 281\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 4/5] END clf__learning_rate=0.01, clf__min_child_samples=10, clf__n_estimators=100, clf__num_leaves=40;, score=0.926 total time=   1.9s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010943 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209588, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5] END clf__learning_rate=0.01, clf__min_child_samples=10, clf__n_estimators=100, clf__num_leaves=40;, score=0.927 total time=   1.8s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010451 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 1/5] END clf__learning_rate=0.05, clf__min_child_samples=20, clf__n_estimators=100, clf__num_leaves=31;, score=nan total time=   2.0s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015695 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 2/5] END clf__learning_rate=0.05, clf__min_child_samples=20, clf__n_estimators=100, clf__num_leaves=31;, score=nan total time=   2.4s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011265 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 3/5] END clf__learning_rate=0.05, clf__min_child_samples=20, clf__n_estimators=100, clf__num_leaves=31;, score=0.964 total time=   1.9s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011655 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 281\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 4/5] END clf__learning_rate=0.05, clf__min_child_samples=20, clf__n_estimators=100, clf__num_leaves=31;, score=0.964 total time=   1.9s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010510 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209588, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5] END clf__learning_rate=0.05, clf__min_child_samples=20, clf__n_estimators=100, clf__num_leaves=31;, score=0.964 total time=   1.9s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009021 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 1/5] END clf__learning_rate=0.01, clf__min_child_samples=20, clf__n_estimators=300, clf__num_leaves=31;, score=nan total time=   3.3s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015633 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 2/5] END clf__learning_rate=0.01, clf__min_child_samples=20, clf__n_estimators=300, clf__num_leaves=31;, score=nan total time=   4.5s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009253 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 3/5] END clf__learning_rate=0.01, clf__min_child_samples=20, clf__n_estimators=300, clf__num_leaves=31;, score=0.954 total time=   3.4s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010253 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 281\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 4/5] END clf__learning_rate=0.01, clf__min_child_samples=20, clf__n_estimators=300, clf__num_leaves=31;, score=0.954 total time=   3.4s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010704 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209588, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5] END clf__learning_rate=0.01, clf__min_child_samples=20, clf__n_estimators=300, clf__num_leaves=31;, score=0.954 total time=   5.1s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009304 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 1/5] END clf__learning_rate=0.1, clf__min_child_samples=30, clf__n_estimators=300, clf__num_leaves=20;, score=nan total time=   2.6s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012029 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 2/5] END clf__learning_rate=0.1, clf__min_child_samples=30, clf__n_estimators=300, clf__num_leaves=20;, score=nan total time=   2.6s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011179 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 3/5] END clf__learning_rate=0.1, clf__min_child_samples=30, clf__n_estimators=300, clf__num_leaves=20;, score=0.971 total time=   2.7s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028774 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 281\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 4/5] END clf__learning_rate=0.1, clf__min_child_samples=30, clf__n_estimators=300, clf__num_leaves=20;, score=0.970 total time=   3.8s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010579 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209588, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5] END clf__learning_rate=0.1, clf__min_child_samples=30, clf__n_estimators=300, clf__num_leaves=20;, score=0.971 total time=   2.7s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008702 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 1/5] END clf__learning_rate=0.05, clf__min_child_samples=10, clf__n_estimators=300, clf__num_leaves=20;, score=nan total time=   2.8s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010897 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 2/5] END clf__learning_rate=0.05, clf__min_child_samples=10, clf__n_estimators=300, clf__num_leaves=20;, score=nan total time=   2.8s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014575 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 3/5] END clf__learning_rate=0.05, clf__min_child_samples=10, clf__n_estimators=300, clf__num_leaves=20;, score=0.969 total time=   4.0s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010333 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 281\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 4/5] END clf__learning_rate=0.05, clf__min_child_samples=10, clf__n_estimators=300, clf__num_leaves=20;, score=0.968 total time=   2.9s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010484 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209588, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5] END clf__learning_rate=0.05, clf__min_child_samples=10, clf__n_estimators=300, clf__num_leaves=20;, score=0.969 total time=   3.1s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009276 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 1/5] END clf__learning_rate=0.05, clf__min_child_samples=30, clf__n_estimators=300, clf__num_leaves=31;, score=nan total time=   4.3s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011957 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 2/5] END clf__learning_rate=0.05, clf__min_child_samples=30, clf__n_estimators=300, clf__num_leaves=31;, score=nan total time=   3.0s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007924 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 3/5] END clf__learning_rate=0.05, clf__min_child_samples=30, clf__n_estimators=300, clf__num_leaves=31;, score=0.970 total time=   3.1s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010508 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 281\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 4/5] END clf__learning_rate=0.05, clf__min_child_samples=30, clf__n_estimators=300, clf__num_leaves=31;, score=0.970 total time=   3.4s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060908 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209588, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5] END clf__learning_rate=0.05, clf__min_child_samples=30, clf__n_estimators=300, clf__num_leaves=31;, score=0.971 total time=   4.7s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009229 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 1/5] END clf__learning_rate=0.1, clf__min_child_samples=20, clf__n_estimators=100, clf__num_leaves=20;, score=nan total time=   1.7s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009581 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 2/5] END clf__learning_rate=0.1, clf__min_child_samples=20, clf__n_estimators=100, clf__num_leaves=20;, score=nan total time=   1.6s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008482 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 3/5] END clf__learning_rate=0.1, clf__min_child_samples=20, clf__n_estimators=100, clf__num_leaves=20;, score=0.967 total time=   1.8s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008787 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 281\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 4/5] END clf__learning_rate=0.1, clf__min_child_samples=20, clf__n_estimators=100, clf__num_leaves=20;, score=0.967 total time=   1.7s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010730 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209588, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5] END clf__learning_rate=0.1, clf__min_child_samples=20, clf__n_estimators=100, clf__num_leaves=20;, score=0.968 total time=   1.9s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017641 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 1/5] END clf__learning_rate=0.01, clf__min_child_samples=30, clf__n_estimators=100, clf__num_leaves=20;, score=nan total time=   1.9s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008456 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 2/5] END clf__learning_rate=0.01, clf__min_child_samples=30, clf__n_estimators=100, clf__num_leaves=20;, score=nan total time=   1.7s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009390 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 3/5] END clf__learning_rate=0.01, clf__min_child_samples=30, clf__n_estimators=100, clf__num_leaves=20;, score=0.911 total time=   1.8s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011037 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 281\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 4/5] END clf__learning_rate=0.01, clf__min_child_samples=30, clf__n_estimators=100, clf__num_leaves=20;, score=0.913 total time=   1.7s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010935 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209588, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5] END clf__learning_rate=0.01, clf__min_child_samples=30, clf__n_estimators=100, clf__num_leaves=20;, score=0.914 total time=   1.7s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009644 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 1/5] END clf__learning_rate=0.01, clf__min_child_samples=30, clf__n_estimators=300, clf__num_leaves=31;, score=nan total time=   5.1s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008962 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 2/5] END clf__learning_rate=0.01, clf__min_child_samples=30, clf__n_estimators=300, clf__num_leaves=31;, score=nan total time=   3.2s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006628 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 3/5] END clf__learning_rate=0.01, clf__min_child_samples=30, clf__n_estimators=300, clf__num_leaves=31;, score=0.954 total time=   3.4s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010727 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 281\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 4/5] END clf__learning_rate=0.01, clf__min_child_samples=30, clf__n_estimators=300, clf__num_leaves=31;, score=0.954 total time=   3.3s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073076 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209588, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5] END clf__learning_rate=0.01, clf__min_child_samples=30, clf__n_estimators=300, clf__num_leaves=31;, score=0.954 total time=   4.0s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010054 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 1/5] END clf__learning_rate=0.01, clf__min_child_samples=30, clf__n_estimators=100, clf__num_leaves=40;, score=nan total time=   1.7s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009366 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 2/5] END clf__learning_rate=0.01, clf__min_child_samples=30, clf__n_estimators=100, clf__num_leaves=40;, score=nan total time=   1.7s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009704 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 3/5] END clf__learning_rate=0.01, clf__min_child_samples=30, clf__n_estimators=100, clf__num_leaves=40;, score=0.926 total time=   1.8s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010288 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 281\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 4/5] END clf__learning_rate=0.01, clf__min_child_samples=30, clf__n_estimators=100, clf__num_leaves=40;, score=0.926 total time=   1.8s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014316 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209588, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5] END clf__learning_rate=0.01, clf__min_child_samples=30, clf__n_estimators=100, clf__num_leaves=40;, score=0.927 total time=   3.5s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009504 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 1/5] END clf__learning_rate=0.1, clf__min_child_samples=30, clf__n_estimators=500, clf__num_leaves=20;, score=nan total time=   3.4s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008604 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 2/5] END clf__learning_rate=0.1, clf__min_child_samples=30, clf__n_estimators=500, clf__num_leaves=20;, score=nan total time=   3.3s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009841 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 3/5] END clf__learning_rate=0.1, clf__min_child_samples=30, clf__n_estimators=500, clf__num_leaves=20;, score=0.972 total time=   4.3s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011032 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 281\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 4/5] END clf__learning_rate=0.1, clf__min_child_samples=30, clf__n_estimators=500, clf__num_leaves=20;, score=0.971 total time=   3.7s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012764 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209588, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5] END clf__learning_rate=0.1, clf__min_child_samples=30, clf__n_estimators=500, clf__num_leaves=20;, score=0.973 total time=   3.5s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009484 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 1/5] END clf__learning_rate=0.1, clf__min_child_samples=20, clf__n_estimators=500, clf__num_leaves=20;, score=nan total time=   3.4s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076030 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 2/5] END clf__learning_rate=0.1, clf__min_child_samples=20, clf__n_estimators=500, clf__num_leaves=20;, score=nan total time=   4.2s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027663 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 3/5] END clf__learning_rate=0.1, clf__min_child_samples=20, clf__n_estimators=500, clf__num_leaves=20;, score=0.972 total time=   4.3s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008977 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 281\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 4/5] END clf__learning_rate=0.1, clf__min_child_samples=20, clf__n_estimators=500, clf__num_leaves=20;, score=0.971 total time=   3.6s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046797 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209588, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5] END clf__learning_rate=0.1, clf__min_child_samples=20, clf__n_estimators=500, clf__num_leaves=20;, score=0.973 total time=   4.4s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010822 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 1/5] END clf__learning_rate=0.05, clf__min_child_samples=20, clf__n_estimators=500, clf__num_leaves=31;, score=nan total time=   4.3s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011700 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 2/5] END clf__learning_rate=0.05, clf__min_child_samples=20, clf__n_estimators=500, clf__num_leaves=31;, score=nan total time=   5.9s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011309 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 3/5] END clf__learning_rate=0.05, clf__min_child_samples=20, clf__n_estimators=500, clf__num_leaves=31;, score=0.972 total time=   4.4s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010506 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 281\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 4/5] END clf__learning_rate=0.05, clf__min_child_samples=20, clf__n_estimators=500, clf__num_leaves=31;, score=0.971 total time=   4.8s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065900 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209588, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5] END clf__learning_rate=0.05, clf__min_child_samples=20, clf__n_estimators=500, clf__num_leaves=31;, score=0.972 total time=   5.7s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008471 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 1/5] END clf__learning_rate=0.1, clf__min_child_samples=30, clf__n_estimators=500, clf__num_leaves=40;, score=nan total time=   4.0s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009189 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 2/5] END clf__learning_rate=0.1, clf__min_child_samples=30, clf__n_estimators=500, clf__num_leaves=40;, score=nan total time=   5.6s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010267 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 3/5] END clf__learning_rate=0.1, clf__min_child_samples=30, clf__n_estimators=500, clf__num_leaves=40;, score=0.974 total time=   4.2s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011241 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 281\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 4/5] END clf__learning_rate=0.1, clf__min_child_samples=30, clf__n_estimators=500, clf__num_leaves=40;, score=0.974 total time=   4.3s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014031 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209588, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5] END clf__learning_rate=0.1, clf__min_child_samples=30, clf__n_estimators=500, clf__num_leaves=40;, score=0.975 total time=   5.9s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010794 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 1/5] END clf__learning_rate=0.01, clf__min_child_samples=30, clf__n_estimators=300, clf__num_leaves=20;, score=nan total time=   3.0s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010906 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 2/5] END clf__learning_rate=0.01, clf__min_child_samples=30, clf__n_estimators=300, clf__num_leaves=20;, score=nan total time=   3.0s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009764 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 3/5] END clf__learning_rate=0.01, clf__min_child_samples=30, clf__n_estimators=300, clf__num_leaves=20;, score=0.948 total time=   4.8s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009641 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 281\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 4/5] END clf__learning_rate=0.01, clf__min_child_samples=30, clf__n_estimators=300, clf__num_leaves=20;, score=0.947 total time=   3.1s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010944 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209588, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5] END clf__learning_rate=0.01, clf__min_child_samples=30, clf__n_estimators=300, clf__num_leaves=20;, score=0.949 total time=   3.1s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008492 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 1/5] END clf__learning_rate=0.05, clf__min_child_samples=30, clf__n_estimators=500, clf__num_leaves=20;, score=nan total time=   5.2s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104793\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012028 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000010\n",
            "[LightGBM] [Info] Start training from score 0.000010\n",
            "[CV 2/5] END clf__learning_rate=0.05, clf__min_child_samples=30, clf__n_estimators=500, clf__num_leaves=20;, score=nan total time=   3.6s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009050 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 3/5] END clf__learning_rate=0.05, clf__min_child_samples=30, clf__n_estimators=500, clf__num_leaves=20;, score=0.970 total time=   4.0s\n",
            "[LightGBM] [Info] Number of positive: 104793, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010419 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 281\n",
            "[LightGBM] [Info] Number of data points in the train set: 209587, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000010\n",
            "[LightGBM] [Info] Start training from score -0.000010\n",
            "[CV 4/5] END clf__learning_rate=0.05, clf__min_child_samples=30, clf__n_estimators=500, clf__num_leaves=20;, score=0.970 total time=   5.7s\n",
            "[LightGBM] [Info] Number of positive: 104794, number of negative: 104794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010419 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 280\n",
            "[LightGBM] [Info] Number of data points in the train set: 209588, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5] END clf__learning_rate=0.05, clf__min_child_samples=30, clf__n_estimators=500, clf__num_leaves=20;, score=0.971 total time=   3.9s\n",
            "[LightGBM] [Info] Number of positive: 130992, number of negative: 130992\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009794 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 278\n",
            "[LightGBM] [Info] Number of data points in the train set: 261984, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "\n",
            "Logistic Regression\n",
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
            "[CV 1/5] END clf__C=0.4832930238571752, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=   9.0s\n",
            "[CV 2/5] END clf__C=0.4832930238571752, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=   8.4s\n",
            "[CV 3/5] END clf__C=0.4832930238571752, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=   8.7s\n",
            "[CV 4/5] END clf__C=0.4832930238571752, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=   8.9s\n",
            "[CV 5/5] END clf__C=0.4832930238571752, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=   9.0s\n",
            "[CV 1/5] END clf__C=61.584821106602604, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=  17.0s\n",
            "[CV 2/5] END clf__C=61.584821106602604, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=  15.7s\n",
            "[CV 3/5] END clf__C=61.584821106602604, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=  18.1s\n",
            "[CV 4/5] END clf__C=61.584821106602604, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=  22.2s\n",
            "[CV 5/5] END clf__C=61.584821106602604, clf__penalty=l2, clf__solver=liblinear;, score=0.972 total time=  18.1s\n",
            "[CV 1/5] END clf__C=37.92690190732246, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  21.2s\n",
            "[CV 2/5] END clf__C=37.92690190732246, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  19.6s\n",
            "[CV 3/5] END clf__C=37.92690190732246, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  19.0s\n",
            "[CV 4/5] END clf__C=37.92690190732246, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  16.9s\n",
            "[CV 5/5] END clf__C=37.92690190732246, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  18.0s\n",
            "[CV 1/5] END clf__C=0.7847599703514611, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  17.5s\n",
            "[CV 2/5] END clf__C=0.7847599703514611, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  16.6s\n",
            "[CV 3/5] END clf__C=0.7847599703514611, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  16.4s\n",
            "[CV 4/5] END clf__C=0.7847599703514611, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  17.0s\n",
            "[CV 5/5] END clf__C=0.7847599703514611, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  17.6s\n",
            "[CV 1/5] END clf__C=23.357214690901213, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  18.7s\n",
            "[CV 2/5] END clf__C=23.357214690901213, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  20.4s\n",
            "[CV 3/5] END clf__C=23.357214690901213, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  18.6s\n",
            "[CV 4/5] END clf__C=23.357214690901213, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  17.6s\n",
            "[CV 5/5] END clf__C=23.357214690901213, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  19.0s\n",
            "[CV 1/5] END clf__C=0.01, clf__penalty=l2, clf__solver=liblinear;, score=0.969 total time=   5.0s\n",
            "[CV 2/5] END clf__C=0.01, clf__penalty=l2, clf__solver=liblinear;, score=0.969 total time=   4.8s\n",
            "[CV 3/5] END clf__C=0.01, clf__penalty=l2, clf__solver=liblinear;, score=0.969 total time=   4.8s\n",
            "[CV 4/5] END clf__C=0.01, clf__penalty=l2, clf__solver=liblinear;, score=0.969 total time=   5.0s\n",
            "[CV 5/5] END clf__C=0.01, clf__penalty=l2, clf__solver=liblinear;, score=0.969 total time=   4.2s\n",
            "[CV 1/5] END clf__C=2.06913808111479, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  18.6s\n",
            "[CV 2/5] END clf__C=2.06913808111479, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  15.0s\n",
            "[CV 3/5] END clf__C=2.06913808111479, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  16.8s\n",
            "[CV 4/5] END clf__C=2.06913808111479, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  18.7s\n",
            "[CV 5/5] END clf__C=2.06913808111479, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  16.5s\n",
            "[CV 1/5] END clf__C=0.016237767391887217, clf__penalty=l2, clf__solver=lbfgs;, score=0.970 total time=  11.9s\n",
            "[CV 2/5] END clf__C=0.016237767391887217, clf__penalty=l2, clf__solver=lbfgs;, score=0.970 total time=  13.2s\n",
            "[CV 3/5] END clf__C=0.016237767391887217, clf__penalty=l2, clf__solver=lbfgs;, score=0.970 total time=  15.3s\n",
            "[CV 4/5] END clf__C=0.016237767391887217, clf__penalty=l2, clf__solver=lbfgs;, score=0.970 total time=  13.9s\n",
            "[CV 5/5] END clf__C=0.016237767391887217, clf__penalty=l2, clf__solver=lbfgs;, score=0.970 total time=  14.5s\n",
            "[CV 1/5] END clf__C=0.06951927961775606, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=   6.0s\n",
            "[CV 2/5] END clf__C=0.06951927961775606, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=   5.9s\n",
            "[CV 3/5] END clf__C=0.06951927961775606, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=   5.8s\n",
            "[CV 4/5] END clf__C=0.06951927961775606, clf__penalty=l2, clf__solver=liblinear;, score=0.970 total time=   5.5s\n",
            "[CV 5/5] END clf__C=0.06951927961775606, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=   5.8s\n",
            "[CV 1/5] END clf__C=61.584821106602604, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  19.7s\n",
            "[CV 2/5] END clf__C=61.584821106602604, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  18.1s\n",
            "[CV 3/5] END clf__C=61.584821106602604, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  20.5s\n",
            "[CV 4/5] END clf__C=61.584821106602604, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  15.3s\n",
            "[CV 5/5] END clf__C=61.584821106602604, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  21.8s\n",
            "[CV 1/5] END clf__C=8.858667904100823, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=  13.8s\n",
            "[CV 2/5] END clf__C=8.858667904100823, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=  13.8s\n",
            "[CV 3/5] END clf__C=8.858667904100823, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=  15.9s\n",
            "[CV 4/5] END clf__C=8.858667904100823, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=  17.3s\n",
            "[CV 5/5] END clf__C=8.858667904100823, clf__penalty=l2, clf__solver=liblinear;, score=0.972 total time=  14.1s\n",
            "[CV 1/5] END clf__C=1.2742749857031335, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=   9.1s\n",
            "[CV 2/5] END clf__C=1.2742749857031335, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=   9.9s\n",
            "[CV 3/5] END clf__C=1.2742749857031335, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=  10.3s\n",
            "[CV 4/5] END clf__C=1.2742749857031335, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=   9.7s\n",
            "[CV 5/5] END clf__C=1.2742749857031335, clf__penalty=l2, clf__solver=liblinear;, score=0.972 total time=   9.5s\n",
            "[CV 1/5] END clf__C=0.18329807108324356, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=   7.6s\n",
            "[CV 2/5] END clf__C=0.18329807108324356, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=   8.1s\n",
            "[CV 3/5] END clf__C=0.18329807108324356, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=   8.7s\n",
            "[CV 4/5] END clf__C=0.18329807108324356, clf__penalty=l2, clf__solver=liblinear;, score=0.970 total time=   8.4s\n",
            "[CV 5/5] END clf__C=0.18329807108324356, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=   8.0s\n",
            "[CV 1/5] END clf__C=5.455594781168514, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=  14.1s\n",
            "[CV 2/5] END clf__C=5.455594781168514, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=  13.8s\n",
            "[CV 3/5] END clf__C=5.455594781168514, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=  14.7s\n",
            "[CV 4/5] END clf__C=5.455594781168514, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=  16.8s\n",
            "[CV 5/5] END clf__C=5.455594781168514, clf__penalty=l2, clf__solver=liblinear;, score=0.972 total time=  12.4s\n",
            "[CV 1/5] END clf__C=0.026366508987303583, clf__penalty=l2, clf__solver=liblinear;, score=0.970 total time=   5.3s\n",
            "[CV 2/5] END clf__C=0.026366508987303583, clf__penalty=l2, clf__solver=liblinear;, score=0.970 total time=   5.4s\n",
            "[CV 3/5] END clf__C=0.026366508987303583, clf__penalty=l2, clf__solver=liblinear;, score=0.970 total time=   5.4s\n",
            "[CV 4/5] END clf__C=0.026366508987303583, clf__penalty=l2, clf__solver=liblinear;, score=0.970 total time=   5.6s\n",
            "[CV 5/5] END clf__C=0.026366508987303583, clf__penalty=l2, clf__solver=liblinear;, score=0.970 total time=   5.6s\n",
            "[CV 1/5] END clf__C=0.29763514416313175, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=   8.5s\n",
            "[CV 2/5] END clf__C=0.29763514416313175, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=   8.5s\n",
            "[CV 3/5] END clf__C=0.29763514416313175, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=   8.7s\n",
            "[CV 4/5] END clf__C=0.29763514416313175, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=   8.6s\n",
            "[CV 5/5] END clf__C=0.29763514416313175, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=   8.4s\n",
            "[CV 1/5] END clf__C=1.2742749857031335, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  16.9s\n",
            "[CV 2/5] END clf__C=1.2742749857031335, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  14.2s\n",
            "[CV 3/5] END clf__C=1.2742749857031335, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  15.1s\n",
            "[CV 4/5] END clf__C=1.2742749857031335, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  15.6s\n",
            "[CV 5/5] END clf__C=1.2742749857031335, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  14.6s\n",
            "[CV 1/5] END clf__C=3.359818286283781, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  18.9s\n",
            "[CV 2/5] END clf__C=3.359818286283781, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  17.7s\n",
            "[CV 3/5] END clf__C=3.359818286283781, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  15.7s\n",
            "[CV 4/5] END clf__C=3.359818286283781, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  18.9s\n",
            "[CV 5/5] END clf__C=3.359818286283781, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  16.3s\n",
            "[CV 1/5] END clf__C=0.11288378916846889, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=   6.0s\n",
            "[CV 2/5] END clf__C=0.11288378916846889, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=   5.9s\n",
            "[CV 3/5] END clf__C=0.11288378916846889, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=   6.0s\n",
            "[CV 4/5] END clf__C=0.11288378916846889, clf__penalty=l2, clf__solver=liblinear;, score=0.970 total time=   7.3s\n",
            "[CV 5/5] END clf__C=0.11288378916846889, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=   7.2s\n",
            "[CV 1/5] END clf__C=0.01, clf__penalty=l2, clf__solver=lbfgs;, score=0.970 total time=  11.5s\n",
            "[CV 2/5] END clf__C=0.01, clf__penalty=l2, clf__solver=lbfgs;, score=0.970 total time=  10.6s\n",
            "[CV 3/5] END clf__C=0.01, clf__penalty=l2, clf__solver=lbfgs;, score=0.970 total time=  11.8s\n",
            "[CV 4/5] END clf__C=0.01, clf__penalty=l2, clf__solver=lbfgs;, score=0.969 total time=  11.5s\n",
            "[CV 5/5] END clf__C=0.01, clf__penalty=l2, clf__solver=lbfgs;, score=0.970 total time=  11.9s\n",
            "[CV 1/5] END clf__C=0.18329807108324356, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  13.2s\n",
            "[CV 2/5] END clf__C=0.18329807108324356, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  18.0s\n",
            "[CV 3/5] END clf__C=0.18329807108324356, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  14.1s\n",
            "[CV 4/5] END clf__C=0.18329807108324356, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  16.9s\n",
            "[CV 5/5] END clf__C=0.18329807108324356, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  12.6s\n",
            "[CV 1/5] END clf__C=14.38449888287663, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  18.5s\n",
            "[CV 2/5] END clf__C=14.38449888287663, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  16.8s\n",
            "[CV 3/5] END clf__C=14.38449888287663, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  19.1s\n",
            "[CV 4/5] END clf__C=14.38449888287663, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  16.2s\n",
            "[CV 5/5] END clf__C=14.38449888287663, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  17.7s\n",
            "[CV 1/5] END clf__C=0.4832930238571752, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  18.6s\n",
            "[CV 2/5] END clf__C=0.4832930238571752, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  16.7s\n",
            "[CV 3/5] END clf__C=0.4832930238571752, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  15.4s\n",
            "[CV 4/5] END clf__C=0.4832930238571752, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  16.2s\n",
            "[CV 5/5] END clf__C=0.4832930238571752, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  14.3s\n",
            "[CV 1/5] END clf__C=100.0, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=  16.8s\n",
            "[CV 2/5] END clf__C=100.0, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=  22.0s\n",
            "[CV 3/5] END clf__C=100.0, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=  18.1s\n",
            "[CV 4/5] END clf__C=100.0, clf__penalty=l2, clf__solver=liblinear;, score=0.971 total time=  21.1s\n",
            "[CV 5/5] END clf__C=100.0, clf__penalty=l2, clf__solver=liblinear;, score=0.972 total time=  17.2s\n",
            "[CV 1/5] END clf__C=0.04281332398719394, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  19.9s\n",
            "[CV 2/5] END clf__C=0.04281332398719394, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  20.5s\n",
            "[CV 3/5] END clf__C=0.04281332398719394, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  18.9s\n",
            "[CV 4/5] END clf__C=0.04281332398719394, clf__penalty=l2, clf__solver=lbfgs;, score=0.970 total time=  17.4s\n",
            "[CV 5/5] END clf__C=0.04281332398719394, clf__penalty=l2, clf__solver=lbfgs;, score=0.971 total time=  19.2s\n",
            "\n",
            "Histogram Gradient Boost\n",
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
            "[CV 1/5] END clf__l2_regularization=0.1, clf__learning_rate=0.2, clf__max_bins=255, clf__max_depth=5, clf__max_leaf_nodes=31, clf__min_samples_leaf=10;, score=0.970 total time=  11.5s\n",
            "[CV 2/5] END clf__l2_regularization=0.1, clf__learning_rate=0.2, clf__max_bins=255, clf__max_depth=5, clf__max_leaf_nodes=31, clf__min_samples_leaf=10;, score=0.970 total time=  11.5s\n",
            "[CV 3/5] END clf__l2_regularization=0.1, clf__learning_rate=0.2, clf__max_bins=255, clf__max_depth=5, clf__max_leaf_nodes=31, clf__min_samples_leaf=10;, score=0.971 total time=  11.7s\n",
            "[CV 4/5] END clf__l2_regularization=0.1, clf__learning_rate=0.2, clf__max_bins=255, clf__max_depth=5, clf__max_leaf_nodes=31, clf__min_samples_leaf=10;, score=0.970 total time=  11.7s\n",
            "[CV 5/5] END clf__l2_regularization=0.1, clf__learning_rate=0.2, clf__max_bins=255, clf__max_depth=5, clf__max_leaf_nodes=31, clf__min_samples_leaf=10;, score=0.971 total time=  12.0s\n",
            "[CV 1/5] END clf__l2_regularization=0.0, clf__learning_rate=0.05, clf__max_bins=128, clf__max_depth=3, clf__max_leaf_nodes=127, clf__min_samples_leaf=10;, score=0.956 total time=  11.4s\n",
            "[CV 2/5] END clf__l2_regularization=0.0, clf__learning_rate=0.05, clf__max_bins=128, clf__max_depth=3, clf__max_leaf_nodes=127, clf__min_samples_leaf=10;, score=0.956 total time=  11.4s\n",
            "[CV 3/5] END clf__l2_regularization=0.0, clf__learning_rate=0.05, clf__max_bins=128, clf__max_depth=3, clf__max_leaf_nodes=127, clf__min_samples_leaf=10;, score=0.956 total time=  12.1s\n",
            "[CV 4/5] END clf__l2_regularization=0.0, clf__learning_rate=0.05, clf__max_bins=128, clf__max_depth=3, clf__max_leaf_nodes=127, clf__min_samples_leaf=10;, score=0.955 total time=  11.7s\n",
            "[CV 5/5] END clf__l2_regularization=0.0, clf__learning_rate=0.05, clf__max_bins=128, clf__max_depth=3, clf__max_leaf_nodes=127, clf__min_samples_leaf=10;, score=0.956 total time=  11.3s\n",
            "[CV 1/5] END clf__l2_regularization=1.0, clf__learning_rate=0.2, clf__max_bins=64, clf__max_depth=7, clf__max_leaf_nodes=15, clf__min_samples_leaf=10;, score=0.970 total time=  12.3s\n",
            "[CV 2/5] END clf__l2_regularization=1.0, clf__learning_rate=0.2, clf__max_bins=64, clf__max_depth=7, clf__max_leaf_nodes=15, clf__min_samples_leaf=10;, score=0.970 total time=  12.2s\n",
            "[CV 3/5] END clf__l2_regularization=1.0, clf__learning_rate=0.2, clf__max_bins=64, clf__max_depth=7, clf__max_leaf_nodes=15, clf__min_samples_leaf=10;, score=0.971 total time=  12.3s\n",
            "[CV 4/5] END clf__l2_regularization=1.0, clf__learning_rate=0.2, clf__max_bins=64, clf__max_depth=7, clf__max_leaf_nodes=15, clf__min_samples_leaf=10;, score=0.970 total time=  12.2s\n",
            "[CV 5/5] END clf__l2_regularization=1.0, clf__learning_rate=0.2, clf__max_bins=64, clf__max_depth=7, clf__max_leaf_nodes=15, clf__min_samples_leaf=10;, score=0.971 total time=  12.3s\n",
            "[CV 1/5] END clf__l2_regularization=1.0, clf__learning_rate=0.05, clf__max_bins=64, clf__max_depth=5, clf__max_leaf_nodes=63, clf__min_samples_leaf=20;, score=0.963 total time=  13.6s\n",
            "[CV 2/5] END clf__l2_regularization=1.0, clf__learning_rate=0.05, clf__max_bins=64, clf__max_depth=5, clf__max_leaf_nodes=63, clf__min_samples_leaf=20;, score=0.963 total time=  13.5s\n",
            "[CV 3/5] END clf__l2_regularization=1.0, clf__learning_rate=0.05, clf__max_bins=64, clf__max_depth=5, clf__max_leaf_nodes=63, clf__min_samples_leaf=20;, score=0.963 total time=  14.0s\n",
            "[CV 4/5] END clf__l2_regularization=1.0, clf__learning_rate=0.05, clf__max_bins=64, clf__max_depth=5, clf__max_leaf_nodes=63, clf__min_samples_leaf=20;, score=0.962 total time=  13.8s\n",
            "[CV 5/5] END clf__l2_regularization=1.0, clf__learning_rate=0.05, clf__max_bins=64, clf__max_depth=5, clf__max_leaf_nodes=63, clf__min_samples_leaf=20;, score=0.963 total time=  13.7s\n",
            "[CV 1/5] END clf__l2_regularization=0.0, clf__learning_rate=0.01, clf__max_bins=128, clf__max_depth=None, clf__max_leaf_nodes=15, clf__min_samples_leaf=20;, score=0.947 total time=  16.0s\n",
            "[CV 2/5] END clf__l2_regularization=0.0, clf__learning_rate=0.01, clf__max_bins=128, clf__max_depth=None, clf__max_leaf_nodes=15, clf__min_samples_leaf=20;, score=0.947 total time=  15.8s\n",
            "[CV 3/5] END clf__l2_regularization=0.0, clf__learning_rate=0.01, clf__max_bins=128, clf__max_depth=None, clf__max_leaf_nodes=15, clf__min_samples_leaf=20;, score=0.947 total time=  16.0s\n",
            "[CV 4/5] END clf__l2_regularization=0.0, clf__learning_rate=0.01, clf__max_bins=128, clf__max_depth=None, clf__max_leaf_nodes=15, clf__min_samples_leaf=20;, score=0.947 total time=  15.6s\n",
            "[CV 5/5] END clf__l2_regularization=0.0, clf__learning_rate=0.01, clf__max_bins=128, clf__max_depth=None, clf__max_leaf_nodes=15, clf__min_samples_leaf=20;, score=0.947 total time=  15.8s\n",
            "[CV 1/5] END clf__l2_regularization=0.1, clf__learning_rate=0.01, clf__max_bins=128, clf__max_depth=None, clf__max_leaf_nodes=63, clf__min_samples_leaf=5;, score=0.958 total time=  23.5s\n",
            "[CV 2/5] END clf__l2_regularization=0.1, clf__learning_rate=0.01, clf__max_bins=128, clf__max_depth=None, clf__max_leaf_nodes=63, clf__min_samples_leaf=5;, score=0.959 total time=  23.1s\n",
            "[CV 3/5] END clf__l2_regularization=0.1, clf__learning_rate=0.01, clf__max_bins=128, clf__max_depth=None, clf__max_leaf_nodes=63, clf__min_samples_leaf=5;, score=0.959 total time=  23.4s\n",
            "[CV 4/5] END clf__l2_regularization=0.1, clf__learning_rate=0.01, clf__max_bins=128, clf__max_depth=None, clf__max_leaf_nodes=63, clf__min_samples_leaf=5;, score=0.958 total time=  23.5s\n",
            "[CV 5/5] END clf__l2_regularization=0.1, clf__learning_rate=0.01, clf__max_bins=128, clf__max_depth=None, clf__max_leaf_nodes=63, clf__min_samples_leaf=5;, score=0.959 total time=  23.3s\n",
            "[CV 1/5] END clf__l2_regularization=1.0, clf__learning_rate=0.01, clf__max_bins=128, clf__max_depth=7, clf__max_leaf_nodes=63, clf__min_samples_leaf=5;, score=0.952 total time=  18.9s\n",
            "[CV 2/5] END clf__l2_regularization=1.0, clf__learning_rate=0.01, clf__max_bins=128, clf__max_depth=7, clf__max_leaf_nodes=63, clf__min_samples_leaf=5;, score=0.953 total time=  19.0s\n",
            "[CV 3/5] END clf__l2_regularization=1.0, clf__learning_rate=0.01, clf__max_bins=128, clf__max_depth=7, clf__max_leaf_nodes=63, clf__min_samples_leaf=5;, score=0.953 total time=  18.9s\n",
            "[CV 4/5] END clf__l2_regularization=1.0, clf__learning_rate=0.01, clf__max_bins=128, clf__max_depth=7, clf__max_leaf_nodes=63, clf__min_samples_leaf=5;, score=0.952 total time=  18.9s\n",
            "[CV 5/5] END clf__l2_regularization=1.0, clf__learning_rate=0.01, clf__max_bins=128, clf__max_depth=7, clf__max_leaf_nodes=63, clf__min_samples_leaf=5;, score=0.953 total time=  18.7s\n",
            "[CV 1/5] END clf__l2_regularization=0.1, clf__learning_rate=0.1, clf__max_bins=64, clf__max_depth=7, clf__max_leaf_nodes=127, clf__min_samples_leaf=5;, score=0.971 total time=  15.9s\n",
            "[CV 2/5] END clf__l2_regularization=0.1, clf__learning_rate=0.1, clf__max_bins=64, clf__max_depth=7, clf__max_leaf_nodes=127, clf__min_samples_leaf=5;, score=0.971 total time=  15.2s\n",
            "[CV 3/5] END clf__l2_regularization=0.1, clf__learning_rate=0.1, clf__max_bins=64, clf__max_depth=7, clf__max_leaf_nodes=127, clf__min_samples_leaf=5;, score=0.971 total time=  15.0s\n",
            "[CV 4/5] END clf__l2_regularization=0.1, clf__learning_rate=0.1, clf__max_bins=64, clf__max_depth=7, clf__max_leaf_nodes=127, clf__min_samples_leaf=5;, score=0.970 total time=  15.4s\n",
            "[CV 5/5] END clf__l2_regularization=0.1, clf__learning_rate=0.1, clf__max_bins=64, clf__max_depth=7, clf__max_leaf_nodes=127, clf__min_samples_leaf=5;, score=0.971 total time=  15.2s\n",
            "[CV 1/5] END clf__l2_regularization=0.1, clf__learning_rate=0.05, clf__max_bins=64, clf__max_depth=10, clf__max_leaf_nodes=63, clf__min_samples_leaf=20;, score=0.969 total time=  19.6s\n",
            "[CV 2/5] END clf__l2_regularization=0.1, clf__learning_rate=0.05, clf__max_bins=64, clf__max_depth=10, clf__max_leaf_nodes=63, clf__min_samples_leaf=20;, score=0.969 total time=  19.5s\n",
            "[CV 3/5] END clf__l2_regularization=0.1, clf__learning_rate=0.05, clf__max_bins=64, clf__max_depth=10, clf__max_leaf_nodes=63, clf__min_samples_leaf=20;, score=0.969 total time=  19.9s\n",
            "[CV 4/5] END clf__l2_regularization=0.1, clf__learning_rate=0.05, clf__max_bins=64, clf__max_depth=10, clf__max_leaf_nodes=63, clf__min_samples_leaf=20;, score=0.969 total time=  20.2s\n",
            "[CV 5/5] END clf__l2_regularization=0.1, clf__learning_rate=0.05, clf__max_bins=64, clf__max_depth=10, clf__max_leaf_nodes=63, clf__min_samples_leaf=20;, score=0.970 total time=  21.1s\n",
            "[CV 1/5] END clf__l2_regularization=0.1, clf__learning_rate=0.1, clf__max_bins=64, clf__max_depth=3, clf__max_leaf_nodes=31, clf__min_samples_leaf=20;, score=0.962 total time=  11.0s\n",
            "[CV 2/5] END clf__l2_regularization=0.1, clf__learning_rate=0.1, clf__max_bins=64, clf__max_depth=3, clf__max_leaf_nodes=31, clf__min_samples_leaf=20;, score=0.962 total time=  10.7s\n",
            "[CV 3/5] END clf__l2_regularization=0.1, clf__learning_rate=0.1, clf__max_bins=64, clf__max_depth=3, clf__max_leaf_nodes=31, clf__min_samples_leaf=20;, score=0.962 total time=  10.8s\n",
            "[CV 4/5] END clf__l2_regularization=0.1, clf__learning_rate=0.1, clf__max_bins=64, clf__max_depth=3, clf__max_leaf_nodes=31, clf__min_samples_leaf=20;, score=0.961 total time=  10.6s\n",
            "[CV 5/5] END clf__l2_regularization=0.1, clf__learning_rate=0.1, clf__max_bins=64, clf__max_depth=3, clf__max_leaf_nodes=31, clf__min_samples_leaf=20;, score=0.962 total time=  11.1s\n",
            "[CV 1/5] END clf__l2_regularization=1.0, clf__learning_rate=0.1, clf__max_bins=255, clf__max_depth=10, clf__max_leaf_nodes=127, clf__min_samples_leaf=10;, score=0.973 total time=  22.1s\n",
            "[CV 2/5] END clf__l2_regularization=1.0, clf__learning_rate=0.1, clf__max_bins=255, clf__max_depth=10, clf__max_leaf_nodes=127, clf__min_samples_leaf=10;, score=0.974 total time=  19.8s\n",
            "[CV 3/5] END clf__l2_regularization=1.0, clf__learning_rate=0.1, clf__max_bins=255, clf__max_depth=10, clf__max_leaf_nodes=127, clf__min_samples_leaf=10;, score=0.974 total time=  19.8s\n",
            "[CV 4/5] END clf__l2_regularization=1.0, clf__learning_rate=0.1, clf__max_bins=255, clf__max_depth=10, clf__max_leaf_nodes=127, clf__min_samples_leaf=10;, score=0.973 total time=  20.3s\n",
            "[CV 5/5] END clf__l2_regularization=1.0, clf__learning_rate=0.1, clf__max_bins=255, clf__max_depth=10, clf__max_leaf_nodes=127, clf__min_samples_leaf=10;, score=0.974 total time=  19.8s\n",
            "[CV 1/5] END clf__l2_regularization=0.0, clf__learning_rate=0.2, clf__max_bins=64, clf__max_depth=3, clf__max_leaf_nodes=15, clf__min_samples_leaf=20;, score=0.966 total time=  10.0s\n",
            "[CV 2/5] END clf__l2_regularization=0.0, clf__learning_rate=0.2, clf__max_bins=64, clf__max_depth=3, clf__max_leaf_nodes=15, clf__min_samples_leaf=20;, score=0.966 total time=  10.0s\n",
            "[CV 3/5] END clf__l2_regularization=0.0, clf__learning_rate=0.2, clf__max_bins=64, clf__max_depth=3, clf__max_leaf_nodes=15, clf__min_samples_leaf=20;, score=0.966 total time=  10.0s\n",
            "[CV 4/5] END clf__l2_regularization=0.0, clf__learning_rate=0.2, clf__max_bins=64, clf__max_depth=3, clf__max_leaf_nodes=15, clf__min_samples_leaf=20;, score=0.965 total time=  10.0s\n",
            "[CV 5/5] END clf__l2_regularization=0.0, clf__learning_rate=0.2, clf__max_bins=64, clf__max_depth=3, clf__max_leaf_nodes=15, clf__min_samples_leaf=20;, score=0.966 total time=   9.9s\n",
            "[CV 1/5] END clf__l2_regularization=1.0, clf__learning_rate=0.01, clf__max_bins=64, clf__max_depth=10, clf__max_leaf_nodes=63, clf__min_samples_leaf=20;, score=0.957 total time=  23.8s\n",
            "[CV 2/5] END clf__l2_regularization=1.0, clf__learning_rate=0.01, clf__max_bins=64, clf__max_depth=10, clf__max_leaf_nodes=63, clf__min_samples_leaf=20;, score=0.957 total time=  25.0s\n",
            "[CV 3/5] END clf__l2_regularization=1.0, clf__learning_rate=0.01, clf__max_bins=64, clf__max_depth=10, clf__max_leaf_nodes=63, clf__min_samples_leaf=20;, score=0.957 total time=  24.8s\n",
            "[CV 4/5] END clf__l2_regularization=1.0, clf__learning_rate=0.01, clf__max_bins=64, clf__max_depth=10, clf__max_leaf_nodes=63, clf__min_samples_leaf=20;, score=0.956 total time=  24.2s\n",
            "[CV 5/5] END clf__l2_regularization=1.0, clf__learning_rate=0.01, clf__max_bins=64, clf__max_depth=10, clf__max_leaf_nodes=63, clf__min_samples_leaf=20;, score=0.957 total time=  22.5s\n",
            "[CV 1/5] END clf__l2_regularization=1.0, clf__learning_rate=0.1, clf__max_bins=128, clf__max_depth=3, clf__max_leaf_nodes=127, clf__min_samples_leaf=10;, score=0.962 total time=  10.8s\n",
            "[CV 2/5] END clf__l2_regularization=1.0, clf__learning_rate=0.1, clf__max_bins=128, clf__max_depth=3, clf__max_leaf_nodes=127, clf__min_samples_leaf=10;, score=0.962 total time=  10.6s\n",
            "[CV 3/5] END clf__l2_regularization=1.0, clf__learning_rate=0.1, clf__max_bins=128, clf__max_depth=3, clf__max_leaf_nodes=127, clf__min_samples_leaf=10;, score=0.962 total time=  11.6s\n",
            "[CV 4/5] END clf__l2_regularization=1.0, clf__learning_rate=0.1, clf__max_bins=128, clf__max_depth=3, clf__max_leaf_nodes=127, clf__min_samples_leaf=10;, score=0.961 total time=  11.4s\n",
            "[CV 5/5] END clf__l2_regularization=1.0, clf__learning_rate=0.1, clf__max_bins=128, clf__max_depth=3, clf__max_leaf_nodes=127, clf__min_samples_leaf=10;, score=0.962 total time=  11.0s\n",
            "[CV 1/5] END clf__l2_regularization=0.1, clf__learning_rate=0.2, clf__max_bins=128, clf__max_depth=None, clf__max_leaf_nodes=127, clf__min_samples_leaf=20;, score=0.977 total time=  20.3s\n",
            "[CV 2/5] END clf__l2_regularization=0.1, clf__learning_rate=0.2, clf__max_bins=128, clf__max_depth=None, clf__max_leaf_nodes=127, clf__min_samples_leaf=20;, score=0.977 total time=  21.1s\n",
            "[CV 3/5] END clf__l2_regularization=0.1, clf__learning_rate=0.2, clf__max_bins=128, clf__max_depth=None, clf__max_leaf_nodes=127, clf__min_samples_leaf=20;, score=0.978 total time=  19.9s\n",
            "[CV 4/5] END clf__l2_regularization=0.1, clf__learning_rate=0.2, clf__max_bins=128, clf__max_depth=None, clf__max_leaf_nodes=127, clf__min_samples_leaf=20;, score=0.977 total time=  20.7s\n",
            "[CV 5/5] END clf__l2_regularization=0.1, clf__learning_rate=0.2, clf__max_bins=128, clf__max_depth=None, clf__max_leaf_nodes=127, clf__min_samples_leaf=20;, score=0.978 total time=  21.1s\n",
            "[CV 1/5] END clf__l2_regularization=0.0, clf__learning_rate=0.1, clf__max_bins=255, clf__max_depth=None, clf__max_leaf_nodes=15, clf__min_samples_leaf=10;, score=0.968 total time=  15.7s\n",
            "[CV 2/5] END clf__l2_regularization=0.0, clf__learning_rate=0.1, clf__max_bins=255, clf__max_depth=None, clf__max_leaf_nodes=15, clf__min_samples_leaf=10;, score=0.968 total time=  15.0s\n",
            "[CV 3/5] END clf__l2_regularization=0.0, clf__learning_rate=0.1, clf__max_bins=255, clf__max_depth=None, clf__max_leaf_nodes=15, clf__min_samples_leaf=10;, score=0.968 total time=  15.1s\n",
            "[CV 4/5] END clf__l2_regularization=0.0, clf__learning_rate=0.1, clf__max_bins=255, clf__max_depth=None, clf__max_leaf_nodes=15, clf__min_samples_leaf=10;, score=0.968 total time=  14.7s\n",
            "[CV 5/5] END clf__l2_regularization=0.0, clf__learning_rate=0.1, clf__max_bins=255, clf__max_depth=None, clf__max_leaf_nodes=15, clf__min_samples_leaf=10;, score=0.969 total time=  14.8s\n",
            "[CV 1/5] END clf__l2_regularization=0.0, clf__learning_rate=0.1, clf__max_bins=64, clf__max_depth=7, clf__max_leaf_nodes=127, clf__min_samples_leaf=20;, score=0.970 total time=  17.1s\n",
            "[CV 2/5] END clf__l2_regularization=0.0, clf__learning_rate=0.1, clf__max_bins=64, clf__max_depth=7, clf__max_leaf_nodes=127, clf__min_samples_leaf=20;, score=0.971 total time=  16.5s\n",
            "[CV 3/5] END clf__l2_regularization=0.0, clf__learning_rate=0.1, clf__max_bins=64, clf__max_depth=7, clf__max_leaf_nodes=127, clf__min_samples_leaf=20;, score=0.971 total time=  16.1s\n",
            "[CV 4/5] END clf__l2_regularization=0.0, clf__learning_rate=0.1, clf__max_bins=64, clf__max_depth=7, clf__max_leaf_nodes=127, clf__min_samples_leaf=20;, score=0.970 total time=  16.6s\n",
            "[CV 5/5] END clf__l2_regularization=0.0, clf__learning_rate=0.1, clf__max_bins=64, clf__max_depth=7, clf__max_leaf_nodes=127, clf__min_samples_leaf=20;, score=0.971 total time=  16.4s\n",
            "[CV 1/5] END clf__l2_regularization=0.0, clf__learning_rate=0.1, clf__max_bins=128, clf__max_depth=10, clf__max_leaf_nodes=127, clf__min_samples_leaf=5;, score=0.974 total time=  20.5s\n",
            "[CV 2/5] END clf__l2_regularization=0.0, clf__learning_rate=0.1, clf__max_bins=128, clf__max_depth=10, clf__max_leaf_nodes=127, clf__min_samples_leaf=5;, score=0.974 total time=  19.8s\n",
            "[CV 3/5] END clf__l2_regularization=0.0, clf__learning_rate=0.1, clf__max_bins=128, clf__max_depth=10, clf__max_leaf_nodes=127, clf__min_samples_leaf=5;, score=0.974 total time=  19.2s\n",
            "[CV 4/5] END clf__l2_regularization=0.0, clf__learning_rate=0.1, clf__max_bins=128, clf__max_depth=10, clf__max_leaf_nodes=127, clf__min_samples_leaf=5;, score=0.973 total time=  19.7s\n",
            "[CV 5/5] END clf__l2_regularization=0.0, clf__learning_rate=0.1, clf__max_bins=128, clf__max_depth=10, clf__max_leaf_nodes=127, clf__min_samples_leaf=5;, score=0.974 total time=  19.3s\n",
            "[CV 1/5] END clf__l2_regularization=1.0, clf__learning_rate=0.01, clf__max_bins=64, clf__max_depth=5, clf__max_leaf_nodes=31, clf__min_samples_leaf=10;, score=0.944 total time=  14.7s\n",
            "[CV 2/5] END clf__l2_regularization=1.0, clf__learning_rate=0.01, clf__max_bins=64, clf__max_depth=5, clf__max_leaf_nodes=31, clf__min_samples_leaf=10;, score=0.943 total time=  14.9s\n",
            "[CV 3/5] END clf__l2_regularization=1.0, clf__learning_rate=0.01, clf__max_bins=64, clf__max_depth=5, clf__max_leaf_nodes=31, clf__min_samples_leaf=10;, score=0.945 total time=  14.7s\n",
            "[CV 4/5] END clf__l2_regularization=1.0, clf__learning_rate=0.01, clf__max_bins=64, clf__max_depth=5, clf__max_leaf_nodes=31, clf__min_samples_leaf=10;, score=0.944 total time=  14.5s\n",
            "[CV 5/5] END clf__l2_regularization=1.0, clf__learning_rate=0.01, clf__max_bins=64, clf__max_depth=5, clf__max_leaf_nodes=31, clf__min_samples_leaf=10;, score=0.945 total time=  14.9s\n",
            "[CV 1/5] END clf__l2_regularization=0.1, clf__learning_rate=0.01, clf__max_bins=255, clf__max_depth=10, clf__max_leaf_nodes=15, clf__min_samples_leaf=20;, score=0.947 total time=  16.2s\n",
            "[CV 2/5] END clf__l2_regularization=0.1, clf__learning_rate=0.01, clf__max_bins=255, clf__max_depth=10, clf__max_leaf_nodes=15, clf__min_samples_leaf=20;, score=0.947 total time=  15.8s\n",
            "[CV 3/5] END clf__l2_regularization=0.1, clf__learning_rate=0.01, clf__max_bins=255, clf__max_depth=10, clf__max_leaf_nodes=15, clf__min_samples_leaf=20;, score=0.947 total time=  15.9s\n",
            "[CV 4/5] END clf__l2_regularization=0.1, clf__learning_rate=0.01, clf__max_bins=255, clf__max_depth=10, clf__max_leaf_nodes=15, clf__min_samples_leaf=20;, score=0.947 total time=  16.4s\n",
            "[CV 5/5] END clf__l2_regularization=0.1, clf__learning_rate=0.01, clf__max_bins=255, clf__max_depth=10, clf__max_leaf_nodes=15, clf__min_samples_leaf=20;, score=0.947 total time=  16.6s\n",
            "[CV 1/5] END clf__l2_regularization=1.0, clf__learning_rate=0.2, clf__max_bins=64, clf__max_depth=3, clf__max_leaf_nodes=63, clf__min_samples_leaf=5;, score=0.966 total time=  10.6s\n",
            "[CV 2/5] END clf__l2_regularization=1.0, clf__learning_rate=0.2, clf__max_bins=64, clf__max_depth=3, clf__max_leaf_nodes=63, clf__min_samples_leaf=5;, score=0.966 total time=  10.2s\n",
            "[CV 3/5] END clf__l2_regularization=1.0, clf__learning_rate=0.2, clf__max_bins=64, clf__max_depth=3, clf__max_leaf_nodes=63, clf__min_samples_leaf=5;, score=0.966 total time=  10.0s\n",
            "[CV 4/5] END clf__l2_regularization=1.0, clf__learning_rate=0.2, clf__max_bins=64, clf__max_depth=3, clf__max_leaf_nodes=63, clf__min_samples_leaf=5;, score=0.965 total time=  10.1s\n",
            "[CV 5/5] END clf__l2_regularization=1.0, clf__learning_rate=0.2, clf__max_bins=64, clf__max_depth=3, clf__max_leaf_nodes=63, clf__min_samples_leaf=5;, score=0.966 total time=  10.0s\n",
            "[CV 1/5] END clf__l2_regularization=1.0, clf__learning_rate=0.1, clf__max_bins=64, clf__max_depth=None, clf__max_leaf_nodes=15, clf__min_samples_leaf=5;, score=0.968 total time=  15.0s\n",
            "[CV 2/5] END clf__l2_regularization=1.0, clf__learning_rate=0.1, clf__max_bins=64, clf__max_depth=None, clf__max_leaf_nodes=15, clf__min_samples_leaf=5;, score=0.968 total time=  14.9s\n",
            "[CV 3/5] END clf__l2_regularization=1.0, clf__learning_rate=0.1, clf__max_bins=64, clf__max_depth=None, clf__max_leaf_nodes=15, clf__min_samples_leaf=5;, score=0.968 total time=  14.3s\n",
            "[CV 4/5] END clf__l2_regularization=1.0, clf__learning_rate=0.1, clf__max_bins=64, clf__max_depth=None, clf__max_leaf_nodes=15, clf__min_samples_leaf=5;, score=0.968 total time=  14.7s\n",
            "[CV 5/5] END clf__l2_regularization=1.0, clf__learning_rate=0.1, clf__max_bins=64, clf__max_depth=None, clf__max_leaf_nodes=15, clf__min_samples_leaf=5;, score=0.969 total time=  14.5s\n",
            "[CV 1/5] END clf__l2_regularization=0.1, clf__learning_rate=0.05, clf__max_bins=128, clf__max_depth=10, clf__max_leaf_nodes=127, clf__min_samples_leaf=10;, score=0.971 total time=  22.9s\n",
            "[CV 2/5] END clf__l2_regularization=0.1, clf__learning_rate=0.05, clf__max_bins=128, clf__max_depth=10, clf__max_leaf_nodes=127, clf__min_samples_leaf=10;, score=0.971 total time=  23.3s\n",
            "[CV 3/5] END clf__l2_regularization=0.1, clf__learning_rate=0.05, clf__max_bins=128, clf__max_depth=10, clf__max_leaf_nodes=127, clf__min_samples_leaf=10;, score=0.971 total time=  22.9s\n",
            "[CV 4/5] END clf__l2_regularization=0.1, clf__learning_rate=0.05, clf__max_bins=128, clf__max_depth=10, clf__max_leaf_nodes=127, clf__min_samples_leaf=10;, score=0.970 total time=  22.5s\n",
            "[CV 5/5] END clf__l2_regularization=0.1, clf__learning_rate=0.05, clf__max_bins=128, clf__max_depth=10, clf__max_leaf_nodes=127, clf__min_samples_leaf=10;, score=0.971 total time=  23.0s\n",
            "[CV 1/5] END clf__l2_regularization=0.0, clf__learning_rate=0.2, clf__max_bins=128, clf__max_depth=7, clf__max_leaf_nodes=31, clf__min_samples_leaf=10;, score=0.972 total time=  13.8s\n",
            "[CV 2/5] END clf__l2_regularization=0.0, clf__learning_rate=0.2, clf__max_bins=128, clf__max_depth=7, clf__max_leaf_nodes=31, clf__min_samples_leaf=10;, score=0.972 total time=  13.7s\n",
            "[CV 3/5] END clf__l2_regularization=0.0, clf__learning_rate=0.2, clf__max_bins=128, clf__max_depth=7, clf__max_leaf_nodes=31, clf__min_samples_leaf=10;, score=0.972 total time=  13.6s\n",
            "[CV 4/5] END clf__l2_regularization=0.0, clf__learning_rate=0.2, clf__max_bins=128, clf__max_depth=7, clf__max_leaf_nodes=31, clf__min_samples_leaf=10;, score=0.972 total time=  13.4s\n",
            "[CV 5/5] END clf__l2_regularization=0.0, clf__learning_rate=0.2, clf__max_bins=128, clf__max_depth=7, clf__max_leaf_nodes=31, clf__min_samples_leaf=10;, score=0.973 total time=  13.2s\n",
            "[CV 1/5] END clf__l2_regularization=0.0, clf__learning_rate=0.2, clf__max_bins=64, clf__max_depth=5, clf__max_leaf_nodes=127, clf__min_samples_leaf=10;, score=0.970 total time=  12.0s\n",
            "[CV 2/5] END clf__l2_regularization=0.0, clf__learning_rate=0.2, clf__max_bins=64, clf__max_depth=5, clf__max_leaf_nodes=127, clf__min_samples_leaf=10;, score=0.970 total time=  12.7s\n",
            "[CV 3/5] END clf__l2_regularization=0.0, clf__learning_rate=0.2, clf__max_bins=64, clf__max_depth=5, clf__max_leaf_nodes=127, clf__min_samples_leaf=10;, score=0.971 total time=  13.0s\n",
            "[CV 4/5] END clf__l2_regularization=0.0, clf__learning_rate=0.2, clf__max_bins=64, clf__max_depth=5, clf__max_leaf_nodes=127, clf__min_samples_leaf=10;, score=0.970 total time=  12.4s\n",
            "[CV 5/5] END clf__l2_regularization=0.0, clf__learning_rate=0.2, clf__max_bins=64, clf__max_depth=5, clf__max_leaf_nodes=127, clf__min_samples_leaf=10;, score=0.971 total time=  11.6s\n",
            "\n",
            "Random Forest classifier\n",
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
            "[CV 1/5] END clf__bootstrap=False, clf__max_depth=10, clf__max_features=log2, clf__min_samples_leaf=1, clf__min_samples_split=10, clf__n_estimators=300;, score=0.948 total time=  23.1s\n",
            "[CV 2/5] END clf__bootstrap=False, clf__max_depth=10, clf__max_features=log2, clf__min_samples_leaf=1, clf__min_samples_split=10, clf__n_estimators=300;, score=0.949 total time=  22.8s\n",
            "[CV 3/5] END clf__bootstrap=False, clf__max_depth=10, clf__max_features=log2, clf__min_samples_leaf=1, clf__min_samples_split=10, clf__n_estimators=300;, score=0.949 total time=  22.8s\n",
            "[CV 4/5] END clf__bootstrap=False, clf__max_depth=10, clf__max_features=log2, clf__min_samples_leaf=1, clf__min_samples_split=10, clf__n_estimators=300;, score=0.947 total time=  22.5s\n",
            "[CV 5/5] END clf__bootstrap=False, clf__max_depth=10, clf__max_features=log2, clf__min_samples_leaf=1, clf__min_samples_split=10, clf__n_estimators=300;, score=0.949 total time=  23.1s\n",
            "[CV 1/5] END clf__bootstrap=True, clf__max_depth=30, clf__max_features=log2, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=300;, score=0.969 total time=  27.1s\n",
            "[CV 2/5] END clf__bootstrap=True, clf__max_depth=30, clf__max_features=log2, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=300;, score=0.969 total time=  29.2s\n",
            "[CV 3/5] END clf__bootstrap=True, clf__max_depth=30, clf__max_features=log2, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=300;, score=0.970 total time=  28.8s\n",
            "[CV 4/5] END clf__bootstrap=True, clf__max_depth=30, clf__max_features=log2, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=300;, score=0.969 total time=  30.2s\n",
            "[CV 5/5] END clf__bootstrap=True, clf__max_depth=30, clf__max_features=log2, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=300;, score=0.970 total time=  27.1s\n",
            "[CV 1/5] END clf__bootstrap=False, clf__max_depth=20, clf__max_features=sqrt, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=200;, score=0.970 total time=  38.6s\n",
            "[CV 2/5] END clf__bootstrap=False, clf__max_depth=20, clf__max_features=sqrt, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=200;, score=0.970 total time=  40.0s\n",
            "[CV 3/5] END clf__bootstrap=False, clf__max_depth=20, clf__max_features=sqrt, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=200;, score=0.970 total time=  36.8s\n",
            "[CV 4/5] END clf__bootstrap=False, clf__max_depth=20, clf__max_features=sqrt, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=200;, score=0.970 total time=  39.1s\n",
            "[CV 5/5] END clf__bootstrap=False, clf__max_depth=20, clf__max_features=sqrt, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=200;, score=0.970 total time=  37.6s\n",
            "[CV 1/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=sqrt, clf__min_samples_leaf=2, clf__min_samples_split=5, clf__n_estimators=500;, score=0.936 total time=  36.7s\n",
            "[CV 2/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=sqrt, clf__min_samples_leaf=2, clf__min_samples_split=5, clf__n_estimators=500;, score=0.936 total time=  38.1s\n",
            "[CV 3/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=sqrt, clf__min_samples_leaf=2, clf__min_samples_split=5, clf__n_estimators=500;, score=0.937 total time=  38.5s\n",
            "[CV 4/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=sqrt, clf__min_samples_leaf=2, clf__min_samples_split=5, clf__n_estimators=500;, score=0.936 total time=  38.5s\n",
            "[CV 5/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=sqrt, clf__min_samples_leaf=2, clf__min_samples_split=5, clf__n_estimators=500;, score=0.937 total time=  38.6s\n",
            "[CV 1/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=log2, clf__min_samples_leaf=4, clf__min_samples_split=5, clf__n_estimators=300;, score=0.935 total time=  14.5s\n",
            "[CV 2/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=log2, clf__min_samples_leaf=4, clf__min_samples_split=5, clf__n_estimators=300;, score=0.937 total time=  13.5s\n",
            "[CV 3/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=log2, clf__min_samples_leaf=4, clf__min_samples_split=5, clf__n_estimators=300;, score=0.935 total time=  14.0s\n",
            "[CV 4/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=log2, clf__min_samples_leaf=4, clf__min_samples_split=5, clf__n_estimators=300;, score=0.934 total time=  13.3s\n",
            "[CV 5/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=log2, clf__min_samples_leaf=4, clf__min_samples_split=5, clf__n_estimators=300;, score=0.935 total time=  13.0s\n",
            "[CV 1/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=sqrt, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=100;, score=0.935 total time=   8.6s\n",
            "[CV 2/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=sqrt, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=100;, score=0.933 total time=   9.1s\n",
            "[CV 3/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=sqrt, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=100;, score=0.937 total time=   9.3s\n",
            "[CV 4/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=sqrt, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=100;, score=0.935 total time=   9.6s\n",
            "[CV 5/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=sqrt, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=100;, score=0.937 total time=   8.9s\n",
            "[CV 1/5] END clf__bootstrap=False, clf__max_depth=30, clf__max_features=auto, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=200;, score=nan total time=   1.1s\n",
            "[CV 2/5] END clf__bootstrap=False, clf__max_depth=30, clf__max_features=auto, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=200;, score=nan total time=   1.2s\n",
            "[CV 3/5] END clf__bootstrap=False, clf__max_depth=30, clf__max_features=auto, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=200;, score=nan total time=   1.2s\n",
            "[CV 4/5] END clf__bootstrap=False, clf__max_depth=30, clf__max_features=auto, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=200;, score=nan total time=   1.2s\n",
            "[CV 5/5] END clf__bootstrap=False, clf__max_depth=30, clf__max_features=auto, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=200;, score=nan total time=   1.2s\n",
            "[CV 1/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=log2, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=300;, score=0.935 total time=  14.5s\n",
            "[CV 2/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=log2, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=300;, score=0.937 total time=  15.3s\n",
            "[CV 3/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=log2, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=300;, score=0.935 total time=  15.7s\n",
            "[CV 4/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=log2, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=300;, score=0.934 total time=  15.5s\n",
            "[CV 5/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=log2, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=300;, score=0.936 total time=  15.1s\n",
            "[CV 1/5] END clf__bootstrap=False, clf__max_depth=10, clf__max_features=auto, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=300;, score=nan total time=   1.2s\n",
            "[CV 2/5] END clf__bootstrap=False, clf__max_depth=10, clf__max_features=auto, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=300;, score=nan total time=   1.1s\n",
            "[CV 3/5] END clf__bootstrap=False, clf__max_depth=10, clf__max_features=auto, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=300;, score=nan total time=   1.2s\n",
            "[CV 4/5] END clf__bootstrap=False, clf__max_depth=10, clf__max_features=auto, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=300;, score=nan total time=   1.2s\n",
            "[CV 5/5] END clf__bootstrap=False, clf__max_depth=10, clf__max_features=auto, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=300;, score=nan total time=   1.2s\n",
            "[CV 1/5] END clf__bootstrap=True, clf__max_depth=5, clf__max_features=sqrt, clf__min_samples_leaf=4, clf__min_samples_split=5, clf__n_estimators=100;, score=0.935 total time=   7.2s\n",
            "[CV 2/5] END clf__bootstrap=True, clf__max_depth=5, clf__max_features=sqrt, clf__min_samples_leaf=4, clf__min_samples_split=5, clf__n_estimators=100;, score=0.934 total time=   6.7s\n",
            "[CV 3/5] END clf__bootstrap=True, clf__max_depth=5, clf__max_features=sqrt, clf__min_samples_leaf=4, clf__min_samples_split=5, clf__n_estimators=100;, score=0.936 total time=   6.9s\n",
            "[CV 4/5] END clf__bootstrap=True, clf__max_depth=5, clf__max_features=sqrt, clf__min_samples_leaf=4, clf__min_samples_split=5, clf__n_estimators=100;, score=0.935 total time=   6.7s\n",
            "[CV 5/5] END clf__bootstrap=True, clf__max_depth=5, clf__max_features=sqrt, clf__min_samples_leaf=4, clf__min_samples_split=5, clf__n_estimators=100;, score=0.936 total time=   8.4s\n",
            "[CV 1/5] END clf__bootstrap=True, clf__max_depth=None, clf__max_features=log2, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=200;, score=0.967 total time=  19.0s\n",
            "[CV 2/5] END clf__bootstrap=True, clf__max_depth=None, clf__max_features=log2, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=200;, score=0.967 total time=  19.1s\n",
            "[CV 3/5] END clf__bootstrap=True, clf__max_depth=None, clf__max_features=log2, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=200;, score=0.967 total time=  18.6s\n",
            "[CV 4/5] END clf__bootstrap=True, clf__max_depth=None, clf__max_features=log2, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=200;, score=0.967 total time=  18.4s\n",
            "[CV 5/5] END clf__bootstrap=True, clf__max_depth=None, clf__max_features=log2, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=200;, score=0.968 total time=  19.1s\n",
            "[CV 1/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=log2, clf__min_samples_leaf=1, clf__min_samples_split=2, clf__n_estimators=100;, score=0.933 total time=   5.6s\n",
            "[CV 2/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=log2, clf__min_samples_leaf=1, clf__min_samples_split=2, clf__n_estimators=100;, score=0.932 total time=   5.5s\n",
            "[CV 3/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=log2, clf__min_samples_leaf=1, clf__min_samples_split=2, clf__n_estimators=100;, score=0.933 total time=   5.5s\n",
            "[CV 4/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=log2, clf__min_samples_leaf=1, clf__min_samples_split=2, clf__n_estimators=100;, score=0.931 total time=   5.3s\n",
            "[CV 5/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=log2, clf__min_samples_leaf=1, clf__min_samples_split=2, clf__n_estimators=100;, score=0.934 total time=   5.3s\n",
            "[CV 1/5] END clf__bootstrap=False, clf__max_depth=None, clf__max_features=sqrt, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=500;, score=0.974 total time= 1.8min\n",
            "[CV 2/5] END clf__bootstrap=False, clf__max_depth=None, clf__max_features=sqrt, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=500;, score=0.975 total time= 1.7min\n",
            "[CV 3/5] END clf__bootstrap=False, clf__max_depth=None, clf__max_features=sqrt, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=500;, score=0.975 total time= 1.8min\n",
            "[CV 4/5] END clf__bootstrap=False, clf__max_depth=None, clf__max_features=sqrt, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=500;, score=0.975 total time= 1.9min\n",
            "[CV 5/5] END clf__bootstrap=False, clf__max_depth=None, clf__max_features=sqrt, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=500;, score=0.975 total time= 1.7min\n",
            "[CV 1/5] END clf__bootstrap=True, clf__max_depth=20, clf__max_features=log2, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=300;, score=0.961 total time=  22.4s\n",
            "[CV 2/5] END clf__bootstrap=True, clf__max_depth=20, clf__max_features=log2, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=300;, score=0.962 total time=  22.4s\n",
            "[CV 3/5] END clf__bootstrap=True, clf__max_depth=20, clf__max_features=log2, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=300;, score=0.962 total time=  23.0s\n",
            "[CV 4/5] END clf__bootstrap=True, clf__max_depth=20, clf__max_features=log2, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=300;, score=0.961 total time=  22.9s\n",
            "[CV 5/5] END clf__bootstrap=True, clf__max_depth=20, clf__max_features=log2, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=300;, score=0.962 total time=  22.4s\n",
            "[CV 1/5] END clf__bootstrap=False, clf__max_depth=30, clf__max_features=sqrt, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=100;, score=0.975 total time=  22.0s\n",
            "[CV 2/5] END clf__bootstrap=False, clf__max_depth=30, clf__max_features=sqrt, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=100;, score=0.975 total time=  21.3s\n",
            "[CV 3/5] END clf__bootstrap=False, clf__max_depth=30, clf__max_features=sqrt, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=100;, score=0.975 total time=  21.9s\n",
            "[CV 4/5] END clf__bootstrap=False, clf__max_depth=30, clf__max_features=sqrt, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=100;, score=0.975 total time=  21.8s\n",
            "[CV 5/5] END clf__bootstrap=False, clf__max_depth=30, clf__max_features=sqrt, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=100;, score=0.976 total time=  21.3s\n",
            "[CV 1/5] END clf__bootstrap=True, clf__max_depth=20, clf__max_features=log2, clf__min_samples_leaf=1, clf__min_samples_split=5, clf__n_estimators=500;, score=0.965 total time=  41.7s\n",
            "[CV 2/5] END clf__bootstrap=True, clf__max_depth=20, clf__max_features=log2, clf__min_samples_leaf=1, clf__min_samples_split=5, clf__n_estimators=500;, score=0.965 total time=  36.8s\n",
            "[CV 3/5] END clf__bootstrap=True, clf__max_depth=20, clf__max_features=log2, clf__min_samples_leaf=1, clf__min_samples_split=5, clf__n_estimators=500;, score=0.966 total time=  37.7s\n",
            "[CV 4/5] END clf__bootstrap=True, clf__max_depth=20, clf__max_features=log2, clf__min_samples_leaf=1, clf__min_samples_split=5, clf__n_estimators=500;, score=0.965 total time=  36.7s\n",
            "[CV 5/5] END clf__bootstrap=True, clf__max_depth=20, clf__max_features=log2, clf__min_samples_leaf=1, clf__min_samples_split=5, clf__n_estimators=500;, score=0.966 total time=  41.0s\n",
            "[CV 1/5] END clf__bootstrap=False, clf__max_depth=30, clf__max_features=log2, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=100;, score=0.967 total time=  14.6s\n",
            "[CV 2/5] END clf__bootstrap=False, clf__max_depth=30, clf__max_features=log2, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=100;, score=0.967 total time=  15.1s\n",
            "[CV 3/5] END clf__bootstrap=False, clf__max_depth=30, clf__max_features=log2, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=100;, score=0.967 total time=  15.0s\n",
            "[CV 4/5] END clf__bootstrap=False, clf__max_depth=30, clf__max_features=log2, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=100;, score=0.967 total time=  15.0s\n",
            "[CV 5/5] END clf__bootstrap=False, clf__max_depth=30, clf__max_features=log2, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=100;, score=0.967 total time=  15.1s\n",
            "[CV 1/5] END clf__bootstrap=False, clf__max_depth=20, clf__max_features=auto, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=500;, score=nan total time=   1.2s\n",
            "[CV 2/5] END clf__bootstrap=False, clf__max_depth=20, clf__max_features=auto, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=500;, score=nan total time=   1.2s\n",
            "[CV 3/5] END clf__bootstrap=False, clf__max_depth=20, clf__max_features=auto, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=500;, score=nan total time=   1.1s\n",
            "[CV 4/5] END clf__bootstrap=False, clf__max_depth=20, clf__max_features=auto, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=500;, score=nan total time=   1.1s\n",
            "[CV 5/5] END clf__bootstrap=False, clf__max_depth=20, clf__max_features=auto, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=500;, score=nan total time=   1.1s\n",
            "[CV 1/5] END clf__bootstrap=True, clf__max_depth=20, clf__max_features=log2, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=200;, score=0.963 total time=  17.0s\n",
            "[CV 2/5] END clf__bootstrap=True, clf__max_depth=20, clf__max_features=log2, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=200;, score=0.963 total time=  16.9s\n",
            "[CV 3/5] END clf__bootstrap=True, clf__max_depth=20, clf__max_features=log2, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=200;, score=0.963 total time=  16.6s\n",
            "[CV 4/5] END clf__bootstrap=True, clf__max_depth=20, clf__max_features=log2, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=200;, score=0.962 total time=  17.1s\n",
            "[CV 5/5] END clf__bootstrap=True, clf__max_depth=20, clf__max_features=log2, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=200;, score=0.963 total time=  17.0s\n",
            "[CV 1/5] END clf__bootstrap=False, clf__max_depth=30, clf__max_features=log2, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=100;, score=0.970 total time=  16.5s\n",
            "[CV 2/5] END clf__bootstrap=False, clf__max_depth=30, clf__max_features=log2, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=100;, score=0.970 total time=  16.8s\n",
            "[CV 3/5] END clf__bootstrap=False, clf__max_depth=30, clf__max_features=log2, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=100;, score=0.970 total time=  17.3s\n",
            "[CV 4/5] END clf__bootstrap=False, clf__max_depth=30, clf__max_features=log2, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=100;, score=0.970 total time=  17.8s\n",
            "[CV 5/5] END clf__bootstrap=False, clf__max_depth=30, clf__max_features=log2, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=100;, score=0.971 total time=  17.1s\n",
            "[CV 1/5] END clf__bootstrap=True, clf__max_depth=30, clf__max_features=log2, clf__min_samples_leaf=1, clf__min_samples_split=10, clf__n_estimators=300;, score=0.974 total time=  33.2s\n",
            "[CV 2/5] END clf__bootstrap=True, clf__max_depth=30, clf__max_features=log2, clf__min_samples_leaf=1, clf__min_samples_split=10, clf__n_estimators=300;, score=0.975 total time=  30.5s\n",
            "[CV 3/5] END clf__bootstrap=True, clf__max_depth=30, clf__max_features=log2, clf__min_samples_leaf=1, clf__min_samples_split=10, clf__n_estimators=300;, score=0.975 total time=  30.3s\n",
            "[CV 4/5] END clf__bootstrap=True, clf__max_depth=30, clf__max_features=log2, clf__min_samples_leaf=1, clf__min_samples_split=10, clf__n_estimators=300;, score=0.975 total time=  30.4s\n",
            "[CV 5/5] END clf__bootstrap=True, clf__max_depth=30, clf__max_features=log2, clf__min_samples_leaf=1, clf__min_samples_split=10, clf__n_estimators=300;, score=0.975 total time=  29.5s\n",
            "[CV 1/5] END clf__bootstrap=True, clf__max_depth=10, clf__max_features=sqrt, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=200;, score=0.953 total time=  17.8s\n",
            "[CV 2/5] END clf__bootstrap=True, clf__max_depth=10, clf__max_features=sqrt, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=200;, score=0.952 total time=  17.9s\n",
            "[CV 3/5] END clf__bootstrap=True, clf__max_depth=10, clf__max_features=sqrt, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=200;, score=0.952 total time=  18.4s\n",
            "[CV 4/5] END clf__bootstrap=True, clf__max_depth=10, clf__max_features=sqrt, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=200;, score=0.952 total time=  18.1s\n",
            "[CV 5/5] END clf__bootstrap=True, clf__max_depth=10, clf__max_features=sqrt, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=200;, score=0.953 total time=  17.8s\n",
            "[CV 1/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=sqrt, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=300;, score=0.936 total time=  23.2s\n",
            "[CV 2/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=sqrt, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=300;, score=0.936 total time=  26.4s\n",
            "[CV 3/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=sqrt, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=300;, score=0.938 total time=  23.7s\n",
            "[CV 4/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=sqrt, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=300;, score=0.936 total time=  24.8s\n",
            "[CV 5/5] END clf__bootstrap=False, clf__max_depth=5, clf__max_features=sqrt, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=300;, score=0.937 total time=  24.9s\n",
            "[CV 1/5] END clf__bootstrap=True, clf__max_depth=None, clf__max_features=log2, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=500;, score=0.967 total time=  49.6s\n",
            "[CV 2/5] END clf__bootstrap=True, clf__max_depth=None, clf__max_features=log2, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=500;, score=0.967 total time=  50.2s\n",
            "[CV 3/5] END clf__bootstrap=True, clf__max_depth=None, clf__max_features=log2, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=500;, score=0.968 total time=  49.1s\n",
            "[CV 4/5] END clf__bootstrap=True, clf__max_depth=None, clf__max_features=log2, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=500;, score=0.967 total time=  43.7s\n",
            "[CV 5/5] END clf__bootstrap=True, clf__max_depth=None, clf__max_features=log2, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=500;, score=0.968 total time=  45.9s\n",
            "[CV 1/5] END clf__bootstrap=False, clf__max_depth=10, clf__max_features=sqrt, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=300;, score=0.952 total time=  42.6s\n",
            "[CV 2/5] END clf__bootstrap=False, clf__max_depth=10, clf__max_features=sqrt, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=300;, score=0.952 total time=  41.7s\n",
            "[CV 3/5] END clf__bootstrap=False, clf__max_depth=10, clf__max_features=sqrt, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=300;, score=0.953 total time=  40.6s\n",
            "[CV 4/5] END clf__bootstrap=False, clf__max_depth=10, clf__max_features=sqrt, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=300;, score=0.952 total time=  41.7s\n",
            "[CV 5/5] END clf__bootstrap=False, clf__max_depth=10, clf__max_features=sqrt, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=300;, score=0.953 total time=  42.1s\n"
          ]
        }
      ],
      "source": [
        "# Train the models\n",
        "print(\"\\nXGBoost\")\n",
        "xgboost_search = run_search(pipeline=xgb,param_config=xgb_params, X_train=X_train_resampled, y_train=y_train_resampled, cv=cv)\n",
        "print(\"\\nLightGBM\")\n",
        "lightgbm_search = run_search(pipeline=lgbm, param_config=lgbm_params, X_train=X_train_resampled, y_train=y_train_resampled, cv=cv)\n",
        "print(\"\\nLogistic Regression\")\n",
        "logistic_regression_search = run_search(pipeline=lrc, param_config=logistic_regression_params, X_train=X_train_resampled, y_train=y_train_resampled, cv=cv)\n",
        "print(\"\\nHistogram Gradient Boost\")\n",
        "hist_grad_boost_search = run_search(pipeline=hgb, param_config=hist_gb_params, X_train=X_train_resampled, y_train=y_train_resampled, cv=cv)\n",
        "print(\"\\nRandom Forest classifier\")\n",
        "random_forests_search = run_search(pipeline=rfc, param_config=random_forest_params, X_train=X_train_resampled, y_train=y_train_resampled,  cv=cv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJXbUAA8134L"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufXNiuSN62qy",
        "outputId": "9d38365f-d376-4cff-87e2-6b678f80e650"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Model: HistogramGradientBoost with CV ROC-AUC= 0.9774\n",
            "Best params:  {'memory': None, 'steps': [('preprocessor', ColumnTransformer(transformers=[('cat',\n",
            "                                 Pipeline(steps=[('encoder',\n",
            "                                                  OneHotEncoder(handle_unknown='ignore',\n",
            "                                                                sparse_output=False))]),\n",
            "                                 ['class_of_worker', 'education',\n",
            "                                  'marital_stat', 'major_industry_code',\n",
            "                                  'major_occupation_code', 'race',\n",
            "                                  'hispanic_origin', 'sex',\n",
            "                                  'member_of_a_labor_union',\n",
            "                                  'reason_for_unemployment',\n",
            "                                  'full_or_part_time_employment_stat',\n",
            "                                  'tax_filer_stat',\n",
            "                                  'detailed_household_and_family_stat',\n",
            "                                  'detailed_household_summary_in_household',\n",
            "                                  'migration_code_change_in_msa',\n",
            "                                  'migration_code_change_in_reg',\n",
            "                                  'migration_code_move_within_reg',\n",
            "                                  'live_in_this_house_1_year_ago',\n",
            "                                  'migration_prev_res_in_sunbelt',\n",
            "                                  'family_members_under_18',\n",
            "                                  'country_of_birth_father',\n",
            "                                  'country_of_birth_mother'])])), ('clf', HistGradientBoostingClassifier(l2_regularization=0.1, learning_rate=0.2,\n",
            "                               max_bins=128, max_leaf_nodes=127,\n",
            "                               random_state=7))], 'transform_input': None, 'verbose': False, 'preprocessor': ColumnTransformer(transformers=[('cat',\n",
            "                                 Pipeline(steps=[('encoder',\n",
            "                                                  OneHotEncoder(handle_unknown='ignore',\n",
            "                                                                sparse_output=False))]),\n",
            "                                 ['class_of_worker', 'education',\n",
            "                                  'marital_stat', 'major_industry_code',\n",
            "                                  'major_occupation_code', 'race',\n",
            "                                  'hispanic_origin', 'sex',\n",
            "                                  'member_of_a_labor_union',\n",
            "                                  'reason_for_unemployment',\n",
            "                                  'full_or_part_time_employment_stat',\n",
            "                                  'tax_filer_stat',\n",
            "                                  'detailed_household_and_family_stat',\n",
            "                                  'detailed_household_summary_in_household',\n",
            "                                  'migration_code_change_in_msa',\n",
            "                                  'migration_code_change_in_reg',\n",
            "                                  'migration_code_move_within_reg',\n",
            "                                  'live_in_this_house_1_year_ago',\n",
            "                                  'migration_prev_res_in_sunbelt',\n",
            "                                  'family_members_under_18',\n",
            "                                  'country_of_birth_father',\n",
            "                                  'country_of_birth_mother'])]), 'clf': HistGradientBoostingClassifier(l2_regularization=0.1, learning_rate=0.2,\n",
            "                               max_bins=128, max_leaf_nodes=127,\n",
            "                               random_state=7), 'preprocessor__force_int_remainder_cols': True, 'preprocessor__n_jobs': None, 'preprocessor__remainder': 'drop', 'preprocessor__sparse_threshold': 0.3, 'preprocessor__transformer_weights': None, 'preprocessor__transformers': [('cat', Pipeline(steps=[('encoder',\n",
            "                 OneHotEncoder(handle_unknown='ignore', sparse_output=False))]), ['class_of_worker', 'education', 'marital_stat', 'major_industry_code', 'major_occupation_code', 'race', 'hispanic_origin', 'sex', 'member_of_a_labor_union', 'reason_for_unemployment', 'full_or_part_time_employment_stat', 'tax_filer_stat', 'detailed_household_and_family_stat', 'detailed_household_summary_in_household', 'migration_code_change_in_msa', 'migration_code_change_in_reg', 'migration_code_move_within_reg', 'live_in_this_house_1_year_ago', 'migration_prev_res_in_sunbelt', 'family_members_under_18', 'country_of_birth_father', 'country_of_birth_mother'])], 'preprocessor__verbose': False, 'preprocessor__verbose_feature_names_out': True, 'preprocessor__cat': Pipeline(steps=[('encoder',\n",
            "                 OneHotEncoder(handle_unknown='ignore', sparse_output=False))]), 'preprocessor__cat__memory': None, 'preprocessor__cat__steps': [('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))], 'preprocessor__cat__transform_input': None, 'preprocessor__cat__verbose': False, 'preprocessor__cat__encoder': OneHotEncoder(handle_unknown='ignore', sparse_output=False), 'preprocessor__cat__encoder__categories': 'auto', 'preprocessor__cat__encoder__drop': None, 'preprocessor__cat__encoder__dtype': <class 'numpy.float64'>, 'preprocessor__cat__encoder__feature_name_combiner': 'concat', 'preprocessor__cat__encoder__handle_unknown': 'ignore', 'preprocessor__cat__encoder__max_categories': None, 'preprocessor__cat__encoder__min_frequency': None, 'preprocessor__cat__encoder__sparse_output': False, 'clf__categorical_features': 'from_dtype', 'clf__class_weight': None, 'clf__early_stopping': 'auto', 'clf__interaction_cst': None, 'clf__l2_regularization': 0.1, 'clf__learning_rate': 0.2, 'clf__loss': 'log_loss', 'clf__max_bins': 128, 'clf__max_depth': None, 'clf__max_features': 1.0, 'clf__max_iter': 100, 'clf__max_leaf_nodes': 127, 'clf__min_samples_leaf': 20, 'clf__monotonic_cst': None, 'clf__n_iter_no_change': 10, 'clf__random_state': 7, 'clf__scoring': 'loss', 'clf__tol': 1e-07, 'clf__validation_fraction': 0.1, 'clf__verbose': 0, 'clf__warm_start': False}\n"
          ]
        }
      ],
      "source": [
        "# Compare the best CV ROC-AUC Scores\n",
        "results = [\n",
        "    ('LogisticRegression', logistic_regression_search.best_score_, logistic_regression_search.best_estimator_),\n",
        "    ('RandomForests', random_forests_search.best_score_, random_forests_search.best_estimator_),\n",
        "    ('HistogramGradientBoost', hist_grad_boost_search.best_score_, hist_grad_boost_search.best_estimator_),\n",
        "    ('XGBoost', xgboost_search.best_score_, xgboost_search.best_estimator_),\n",
        "    ('LightGBM', lightgbm_search.best_score_, lightgbm_search.best_estimator_)\n",
        "]\n",
        "\n",
        "# Get top results\n",
        "top_results = sorted(results, key=lambda x:x[1], reverse=True)\n",
        "\n",
        "# Get the Best Model\n",
        "best_model_name, best_cv_auc, best_model = top_results[0]\n",
        "\n",
        "print(f\"Best Model: {best_model_name} with CV ROC-AUC={best_cv_auc: .4f}\")\n",
        "print(\"Best params: \", best_model.get_params())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "OsYnrUhq89vY",
        "outputId": "ef4da49f-4865-4f4e-ab21-047252a55f43"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;encoder&#x27;,\n",
              "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
              "                                                                                 sparse_output=False))]),\n",
              "                                                  [&#x27;class_of_worker&#x27;,\n",
              "                                                   &#x27;education&#x27;, &#x27;marital_stat&#x27;,\n",
              "                                                   &#x27;major_industry_code&#x27;,\n",
              "                                                   &#x27;major_occupation_code&#x27;,\n",
              "                                                   &#x27;race&#x27;, &#x27;hispanic_origin&#x27;,\n",
              "                                                   &#x27;sex&#x27;,\n",
              "                                                   &#x27;member_of_a_labor_union&#x27;,\n",
              "                                                   &#x27;reason_for_unemployment&#x27;,\n",
              "                                                   &#x27;full_or_part_t...\n",
              "                                                   &#x27;migration_code_change_in_msa&#x27;,\n",
              "                                                   &#x27;migration_code_change_in_reg&#x27;,\n",
              "                                                   &#x27;migration_code_move_within_reg&#x27;,\n",
              "                                                   &#x27;live_in_this_house_1_year_ago&#x27;,\n",
              "                                                   &#x27;migration_prev_res_in_sunbelt&#x27;,\n",
              "                                                   &#x27;family_members_under_18&#x27;,\n",
              "                                                   &#x27;country_of_birth_father&#x27;,\n",
              "                                                   &#x27;country_of_birth_mother&#x27;])])),\n",
              "                (&#x27;clf&#x27;,\n",
              "                 HistGradientBoostingClassifier(l2_regularization=0.1,\n",
              "                                                learning_rate=0.2, max_bins=128,\n",
              "                                                max_leaf_nodes=127,\n",
              "                                                random_state=7))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;encoder&#x27;,\n",
              "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
              "                                                                                 sparse_output=False))]),\n",
              "                                                  [&#x27;class_of_worker&#x27;,\n",
              "                                                   &#x27;education&#x27;, &#x27;marital_stat&#x27;,\n",
              "                                                   &#x27;major_industry_code&#x27;,\n",
              "                                                   &#x27;major_occupation_code&#x27;,\n",
              "                                                   &#x27;race&#x27;, &#x27;hispanic_origin&#x27;,\n",
              "                                                   &#x27;sex&#x27;,\n",
              "                                                   &#x27;member_of_a_labor_union&#x27;,\n",
              "                                                   &#x27;reason_for_unemployment&#x27;,\n",
              "                                                   &#x27;full_or_part_t...\n",
              "                                                   &#x27;migration_code_change_in_msa&#x27;,\n",
              "                                                   &#x27;migration_code_change_in_reg&#x27;,\n",
              "                                                   &#x27;migration_code_move_within_reg&#x27;,\n",
              "                                                   &#x27;live_in_this_house_1_year_ago&#x27;,\n",
              "                                                   &#x27;migration_prev_res_in_sunbelt&#x27;,\n",
              "                                                   &#x27;family_members_under_18&#x27;,\n",
              "                                                   &#x27;country_of_birth_father&#x27;,\n",
              "                                                   &#x27;country_of_birth_mother&#x27;])])),\n",
              "                (&#x27;clf&#x27;,\n",
              "                 HistGradientBoostingClassifier(l2_regularization=0.1,\n",
              "                                                learning_rate=0.2, max_bins=128,\n",
              "                                                max_leaf_nodes=127,\n",
              "                                                random_state=7))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>preprocessor: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;encoder&#x27;,\n",
              "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
              "                                                                sparse_output=False))]),\n",
              "                                 [&#x27;class_of_worker&#x27;, &#x27;education&#x27;,\n",
              "                                  &#x27;marital_stat&#x27;, &#x27;major_industry_code&#x27;,\n",
              "                                  &#x27;major_occupation_code&#x27;, &#x27;race&#x27;,\n",
              "                                  &#x27;hispanic_origin&#x27;, &#x27;sex&#x27;,\n",
              "                                  &#x27;member_of_a_labor_union&#x27;,\n",
              "                                  &#x27;reason_for_unemployment&#x27;,\n",
              "                                  &#x27;full_or_part_time_employment_stat&#x27;,\n",
              "                                  &#x27;tax_filer_stat&#x27;,\n",
              "                                  &#x27;detailed_household_and_family_stat&#x27;,\n",
              "                                  &#x27;detailed_household_summary_in_household&#x27;,\n",
              "                                  &#x27;migration_code_change_in_msa&#x27;,\n",
              "                                  &#x27;migration_code_change_in_reg&#x27;,\n",
              "                                  &#x27;migration_code_move_within_reg&#x27;,\n",
              "                                  &#x27;live_in_this_house_1_year_ago&#x27;,\n",
              "                                  &#x27;migration_prev_res_in_sunbelt&#x27;,\n",
              "                                  &#x27;family_members_under_18&#x27;,\n",
              "                                  &#x27;country_of_birth_father&#x27;,\n",
              "                                  &#x27;country_of_birth_mother&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>cat</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;class_of_worker&#x27;, &#x27;education&#x27;, &#x27;marital_stat&#x27;, &#x27;major_industry_code&#x27;, &#x27;major_occupation_code&#x27;, &#x27;race&#x27;, &#x27;hispanic_origin&#x27;, &#x27;sex&#x27;, &#x27;member_of_a_labor_union&#x27;, &#x27;reason_for_unemployment&#x27;, &#x27;full_or_part_time_employment_stat&#x27;, &#x27;tax_filer_stat&#x27;, &#x27;detailed_household_and_family_stat&#x27;, &#x27;detailed_household_summary_in_household&#x27;, &#x27;migration_code_change_in_msa&#x27;, &#x27;migration_code_change_in_reg&#x27;, &#x27;migration_code_move_within_reg&#x27;, &#x27;live_in_this_house_1_year_ago&#x27;, &#x27;migration_prev_res_in_sunbelt&#x27;, &#x27;family_members_under_18&#x27;, &#x27;country_of_birth_father&#x27;, &#x27;country_of_birth_mother&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div> </div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>HistGradientBoostingClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.html\">?<span>Documentation for HistGradientBoostingClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>HistGradientBoostingClassifier(l2_regularization=0.1, learning_rate=0.2,\n",
              "                               max_bins=128, max_leaf_nodes=127,\n",
              "                               random_state=7)</pre></div> </div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('preprocessor',\n",
              "                 ColumnTransformer(transformers=[('cat',\n",
              "                                                  Pipeline(steps=[('encoder',\n",
              "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
              "                                                                                 sparse_output=False))]),\n",
              "                                                  ['class_of_worker',\n",
              "                                                   'education', 'marital_stat',\n",
              "                                                   'major_industry_code',\n",
              "                                                   'major_occupation_code',\n",
              "                                                   'race', 'hispanic_origin',\n",
              "                                                   'sex',\n",
              "                                                   'member_of_a_labor_union',\n",
              "                                                   'reason_for_unemployment',\n",
              "                                                   'full_or_part_t...\n",
              "                                                   'migration_code_change_in_msa',\n",
              "                                                   'migration_code_change_in_reg',\n",
              "                                                   'migration_code_move_within_reg',\n",
              "                                                   'live_in_this_house_1_year_ago',\n",
              "                                                   'migration_prev_res_in_sunbelt',\n",
              "                                                   'family_members_under_18',\n",
              "                                                   'country_of_birth_father',\n",
              "                                                   'country_of_birth_mother'])])),\n",
              "                ('clf',\n",
              "                 HistGradientBoostingClassifier(l2_regularization=0.1,\n",
              "                                                learning_rate=0.2, max_bins=128,\n",
              "                                                max_leaf_nodes=127,\n",
              "                                                random_state=7))])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fit the Best Model\n",
        "best_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fCYm0PRhBlWG"
      },
      "outputs": [],
      "source": [
        "# Predict the probabilities on validation dataset\n",
        "y_val_prob = best_model.predict_proba(X_val)[:, 1] if hasattr(best_model, 'predict_proba') else best_model.decision_function(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQhbJaUACzrW",
        "outputId": "6333b259-19f6-4a4d-ef05-f5b52f492b97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chosen Threshold=0.24000000000000002 (F1 on validation=0.516775396085741)\n"
          ]
        }
      ],
      "source": [
        "# Threshold to maximize the F1 metrics on validatino dataset\n",
        "thresholds = np.linspace(0.1, 0.9, 81)\n",
        "f1s = []\n",
        "for t in thresholds:\n",
        "  y_val_pred = (y_val_prob >= t).astype(int)\n",
        "  f1s.append(f1_score(y_val, y_val_pred))\n",
        "best_t = thresholds[int(np.argmax(f1s))]\n",
        "print(f\"Chosen Threshold={best_t} (F1 on validation={max(f1s)})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6K3NktODlNW",
        "outputId": "13384176-e5be-425d-e447-edbadec4ff19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Metrics  {'Accuracy': 0.9302, 'Precision': 0.4508, 'Recall': 0.5724, 'F1': 0.5044, 'ROC_AUC': np.float64(0.7631), 'PR_AUC': np.float64(0.2846)}\n"
          ]
        }
      ],
      "source": [
        "# Final Evaluation on Test Dataset\n",
        "y_test_proba = best_model.predict_proba(X_test)[:, 1] if hasattr(best_model, 'predict_proba') else best_model.decision_function(X_test)\n",
        "y_test_pred = (y_test_proba >= best_t).astype(int)\n",
        "\n",
        "test_metrics = {\n",
        "    'Accuracy': accuracy_score(y_test, y_test_pred),\n",
        "    'Precision': precision_score(y_test, y_test_pred),\n",
        "    'Recall': recall_score(y_test, y_test_pred),\n",
        "    'F1': f1_score(y_test, y_test_pred),\n",
        "    'ROC_AUC': roc_auc_score(y_test, y_test_pred),\n",
        "    'PR_AUC': average_precision_score(y_test, y_test_pred)\n",
        "}\n",
        "\n",
        "print(\"Test Metrics \", {key: round(value, 4) for key, value in test_metrics.items()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "8fxOI_fPpggX",
        "outputId": "c8bc9bc4-8f58-4aee-98cd-a1a8a780d4cb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"results\",\n  \"rows\": 29929,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"proba\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13689728725802638,\n        \"min\": 0.00011490514366741103,\n        \"max\": 0.9190185480351936,\n        \"num_unique_values\": 15099,\n        \"samples\": [\n          0.001997946287900642,\n          0.22710001032221286\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "results"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-f141c5cb-266b-4759-9a52-ad06f76b3b63\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>proba</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8459</th>\n",
              "      <td>0</td>\n",
              "      <td>0.005505</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91636</th>\n",
              "      <td>0</td>\n",
              "      <td>0.147375</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119367</th>\n",
              "      <td>0</td>\n",
              "      <td>0.044389</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104524</th>\n",
              "      <td>0</td>\n",
              "      <td>0.101283</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190996</th>\n",
              "      <td>0</td>\n",
              "      <td>0.033984</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28759</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000115</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70837</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000583</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46455</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000283</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74624</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000115</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133194</th>\n",
              "      <td>0</td>\n",
              "      <td>0.075320</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29929 rows  3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f141c5cb-266b-4759-9a52-ad06f76b3b63')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f141c5cb-266b-4759-9a52-ad06f76b3b63 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f141c5cb-266b-4759-9a52-ad06f76b3b63');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b6ed9863-2506-4bd6-ba8b-dac5bde8f92c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b6ed9863-2506-4bd6-ba8b-dac5bde8f92c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b6ed9863-2506-4bd6-ba8b-dac5bde8f92c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_910957ff-e3cb-49b6-a187-a6472ca24093\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_910957ff-e3cb-49b6-a187-a6472ca24093 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        label     proba  pred\n",
              "8459        0  0.005505     0\n",
              "91636       0  0.147375     0\n",
              "119367      0  0.044389     0\n",
              "104524      0  0.101283     0\n",
              "190996      0  0.033984     0\n",
              "...       ...       ...   ...\n",
              "28759       0  0.000115     0\n",
              "70837       0  0.000583     0\n",
              "46455       0  0.000283     0\n",
              "74624       0  0.000115     0\n",
              "133194      0  0.075320     0\n",
              "\n",
              "[29929 rows x 3 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test = y_test.copy()\n",
        "\n",
        "# Get probabilities\n",
        "proba = (\n",
        "    best_model.predict_proba(X_test)[:, 1]\n",
        "    if hasattr(best_model, \"predict_proba\")\n",
        "    else best_model.decision_function(X_test)\n",
        ")\n",
        "\n",
        "results = pd.DataFrame(\n",
        "    {\n",
        "        \"label\": y_test.values,\n",
        "        \"proba\": proba,\n",
        "    },\n",
        "    index=y_test.index\n",
        ")\n",
        "\n",
        "# Apply threshold\n",
        "results[\"pred\"] = (results[\"proba\"] >= best_t).astype(int)\n",
        "\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "xdF-Y2etF2_B",
        "outputId": "a22d1617-64bd-4776-8a85-5b5562cd7e70"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fpr, tpr, roc_thresholds = roc_curve(y_test, y_test_proba)\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {test_metrics[\"ROC_AUC\"]:0.4f})') #  ROC Curve\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier (Area = 0.5)') # diagonal baseline\n",
        "\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
        "plt.ylabel('True Positive Rate (Recall)')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2) # Precision-Recall Curve Plot\n",
        "\n",
        "precision, recall, pr_thresholds = precision_recall_curve(y_test, y_test_proba) # Calculate Precision-Recall pairs\n",
        "\n",
        "pr_auc = auc(recall, precision) # Area under the curve\n",
        "\n",
        "plt.plot(recall, precision, color='green', lw=2, label=f'PR curve (area = {pr_auc:0.4f})') # PR Curve\n",
        "\n",
        "no_skill = len(y_test[y_test==1]) / len(y_test) # Bo skill Baseline is the ratio of positive class (P / (P+N))\n",
        "plt.plot([0, 1], [no_skill, no_skill], color='navy', lw=2, linestyle='--', label=f'No Skill Baseline (P/(P+N) = {no_skill:0.4f})')\n",
        "\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvE5iQ_N4YJ3"
      },
      "source": [
        "# Deployment (Offline Saving and Loading)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3um44Sw-GQ2g",
        "outputId": "f50a7eb7-1751-4de3-c803-7a4f22642c6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/JPMC Assessment/models/classifier.joblib']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Save the model and use for deployment inference\n",
        "joblib.dump({\n",
        "    'model': best_model,\n",
        "    'threshold': float(best_t),\n",
        "    'numeric_features': numeric_features,\n",
        "    'categorical_features': categorical_features,\n",
        "}, 'models/classifier.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiOsXKu_HGE8"
      },
      "outputs": [],
      "source": [
        "## Use the deployed model for inference\n",
        "artifact = joblib.load('models/classifier.joblib')\n",
        "model = artifact['model']\n",
        "threshold = artifact['threshold']\n",
        "\n",
        "# Infer on Sample test data\n",
        "prob = model.predict_proba(X_test[:10])[:, 1] if hasattr(model, 'predict_proba') else model.decision_function(X_test[:10])\n",
        "pred = (prob >= threshold).astype(int)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
